

Context from codebase:


Context from Wiki:

Wiki Page: /SCOPE Language/SCOPE Tutorial
# Overview

SCOPE (_Structured Computation Optimized for Parallel Execution_) refers to the compute/query system in Cosmos which includes the SCOPE query language, the SCOPE optimizer, and the SCOPE runtime. SCOPE's declarative language closely resembles SQL and is used to process data in Cosmos. In addition, it can be used to express advanced analytics tasks and operate seamlessly on cloud-scale data. One of the unique features of SCOPE is the combination of the SQL-like declarative language with the extensibility and programmability that's provided by C# and Python. 

Use the SCOPE Tutorial as an introduction to understanding the basics of SCOPE. For more detailed information about SCOPE query language, see the [SCOPE Language Reference](/SCOPE-Language/SCOPE-Language-Reference).

## Prerequisites
- x64 Windows installation
- Windows PowerShell
- [Visual Studio 2019 (recommended) or 2017](https://visualstudio.microsoft.com/vs/older-downloads/) + [SCOPE Studio](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3015/SCOPE-Studio)
- [SCOPE SDK](https://mscosmos.visualstudio.com/ScopeTutorial/_wiki/wikis/ScopeTutorial.wiki/516/SCOPE-SDK)
- [Sandbox access](/Cosmos-Tools-and-SDKs/Sandbox-access)
##Sample SCOPE scripts

Browse the Git Repo for [SCOPE language code samples](https://mscosmos.visualstudio.com/DefaultCollection/_git/CosmosSamples?path=%2FScopeLanguage) or use the samples readily available in the Cosmos [sandbox](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Running-scripts-in-the-cluster/Accessing-the-sandbox-VC).
##Community resources
- Search [Stack Overflow](https://stackoverflow.microsoft.com/) with questions about Cosmos. (Make sure to tag questions with _[SCOPE + Cosmos]_ or _[Spark + Cosmos]_ for targeted questions and answers.)
- [Join Cosmos Discussion](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join) to see the latest questions and answers from the team. 
- Send questions to the Cosmos team via [Cosmos Discussion](mailto:cosmdisc@microsoft.com).


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Core concepts
#Overview

Before running a script, review the following basics concepts:

- A SCOPE script maps some input to some output via a processing step:

     **INPUT -> PROCESS -> OUTPUT**

- Inputs and outputs are Cosmos streams. A stream is a file-like data stored in Cosmos. If a script is run locally as a stream, it is just a normal file like any other on a machine.

- A typical SCOPE script has at least one input and at least one output -- though there are special cases where they can have zero inputs or zero outputs.

- During the process phase, an input stream is transformed into a rowset. Rowsets are how SCOPE internally passes data during script execution. The rowset may also be transformed to other rowsets.

The following topics are covered in this section:
- [Code sample styles and conventions](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Code-sample-styles-and-conventions)
- [Script basics](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Script-basics)
- [Streams](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Streams)
- [Views](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Views)
- [Extractors and outputters](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Extractors-and-outputters) 
- [Data types](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Data-types)


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Core concepts/Script basics
#Overview
Below is an example of the conceptually smallest SCOPE script:

```scala
test_input = 
 EXTRACT
   FirstName : string,
   LastName : string,
   Age : int
 FROM
   "/local/Samples/SampleData/test_input.tsv"
   USING DefaultTextExtractor();
 
OUTPUT test_input 
 TO "/local/users/<your alias>/output.tsv"
 USING DefaultTextOutputter();
```

## Script structure

Two SCOPE statements exist in the example above:

- [**EXTRACT**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT) command builds a **rowset** called _test_input_ from an input stream.
- [**OUTPUT**](/SCOPE-Language/SCOPE-Language-Reference/OUTPUT-statement) command writes that **rowset** to an output stream.

## Reading data

- The [**EXTRACT**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT) command transforms a stream into a rowset.
- The **EXTRACT** command uses [**DefaultTextExtractor**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/DefaultTextExtractor) to parse the stream. By default [**DefaultTextExtractor**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/DefaultTextExtractor) assumes it is reading a TSV (tab-separated-value) file.
- The [**DefaultTextExtractor**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/DefaultTextExtractor) command does not know the schema of the file it is reading, so always provide the schema.

## Writing data

- The rows that are read from the **EXTRACT** statement flow into a rowset we named **test_input**.
- The [**OUTPUT**](/SCOPE-Language/SCOPE-Language-Reference/OUTPUT-statement) command sends the rows from rowset **test_input** to an output stream.
- The [**OUTPUT**](/SCOPE-Language/SCOPE-Language-Reference/OUTPUT-statement) command uses [**DefaultTextOutputter**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/DefaultTextOutputter) to format the row into a TSV format.

**Important**

- Notice that some keywords are capitalized. For example: [**EXTRACT**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT), [**FROM**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT/FROM), and [**USING**](/SCOPE-Language/SCOPE-Language-Reference/User-defined-operators-\(UDOs\)/Clauses-and-Functions/USING). SCOPE takes capitalization very seriously, so writing _**extract**_ instead of **EXTRACT** will cause a compilation error. It's important to capitalize every SCOPE keyword when writing a script.
- Calling **DefaultTextExtractor** without any arguments is equivalent to **DefaultTextExtractor** ( delimiter: '\t' ) which explicitly identifies that the file is delimited by tabs.
- Assume that all stream names are case-sensitive. When running locally, it doesn't matter but when running in the cluster it does. Likewise, stick to the "/" separator. It works both locally and for remote execution unlike "\\" which only works on local execution.
- <font color="red">**[New!]**</font> Paths with trailing forward or backward slash character are not paths to files. Error `E_CSC_USER_PATHDOESNOTCONTAINFILENAME` will be raised  for such invalid file path.

  The following example shows a path for the VIEW statement that will cause an **error**.
  ```scala
  VIEW @“/path/filename.view/”;
  ```

##Full expression support for paths in the script

Any constant-foldable expression can be used in paths for statements like `EXTRACT`, `OUTPUT`, and `RESOURCE`, but it has to be computable during compilation, and the expression can be inlined. It does not need to be pulled up in its own variable.

``` sql
 DECLARE @prefix = EXISTS(“a/b/v2”) ? “a/b/v2” : “a/b/v1”; 
 data = 
     EXTRACT a int, b string 
     FROM 
         string.Format(“{0}/{1}”, @prefix, “myfile.txt”), 
         @prefix + “/c/mynextfile.txt” 
USING Extractors.Csv(); 
```

Note: There are minor limitations due to other supported syntax.

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Core concepts/Streams
#Overview
Streams are files stored in a VC that users read from to process data. Reading data means reading from the following two types of streams:

## Structured streams

Structured streams are optimized for Cosmos data storage and access. Since the format of a structured stream contains the schema that Cosmos understands, there is a special syntax to read and write to them (**EXTRACT** isn't used).

## Unstructured streams

Unstructured streams are any stream that isn't structured. The key characteristic of these streams is that Cosmos does NOT inherently know about their schema or format. Thus, the schema must be defined by the user. Samples of these are CSV, TSV, and Parquet.

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Core concepts/Views
#Overview

SCOPE Views are a mechanism that encapsulates simplified access to complex data in Cosmos. A **VIEW** simplifies reading from streams and is used to take on the responsibility of encapsulating data of multiple rowsets, while doing all of the joining and filtering for the user. 

## Examples
 
- A dataset has a complicated Extractor with sophisticated mechanisms for extracting various schemas from the data. In this case, the owner of the data may decide to implement some views to encapsulate some of the common schemas users want to retrieve from the data. Users can then write jobs that read from the views, thereby bypassing the need to deal with the extractor. 
- A data owner wants to provide simple, seamless access to a year's worth of historical data even though the data format and extractor changed six months ago (the schema, however, did not change). Instead of requiring consumers of the data to write two different extracts for the data ranges, a view could be written to hide this complexity and consumers would simply write a job to read from the single view.
 
<hr>

##View Definition

The syntax for view definition is as follows:

```xml
CREATE VIEW view_name SCHEMA ( <column_definition> [,...n] )  
    [ PARAMS <param_definition> [,...n]) ]
AS BEGIN
    <view_body>
END;

<column definition> ::=
    column_name:column_type

<param_definition> ::=
    param_name param_type [DEFAULT = value_expression]

```

## Arguments

**<view_name>**
The name you want to give the view.

**<column_name>**
The name of the column.

**<column_type>**
The type of the column; can be any allowed SCOPE type.

**<param_name>**
Name given to the parameter. This is the name used by the caller when providing the parameter values. This is equivalent to the new parameters introduced in SCOPE. Notice that old parameters are not supported. View parameters follow the general rules for parameters in the SCOPE language.

**<param_type>**
The type of the parameter. Can be any of the built-in SCOPE types. View parameters follow the general rules for parameters in the SCOPE language.

**<value_expression>**
This is an expression recognized by SCOPE which specifies the default value for this parameter if it is not supplied when the view is called.

**<view_body>**
A sequence of scope commands. **IMPORT**, **EXPORT**, and **[OUTPUT](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/413/OUTPUT-statement)** commands and #CS blocks are not allowed in the view_body.

<hr>

##View Usage
Views are used in calling scripts by directly reading from them, as would be done from any other rowset. There are two supported syntaxes for reading from a view. The first is to separately declare the instance of the view with the View keyword:


```scala
relvar = VIEW "myView.script" 
PARAMS (arg="myExtractorArg", start=DateTime.Parse("03-08-2010"));

SELECT a,b,c FROM relvar WHERE a < 3;
```


The second way to use a view is to collapse the above two statements such that the **[SELECT](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3156/SELECT)** reads directly from the VIEW specification:

```scala
SELECT a,b,c FROM 
(VIEW "myView.script" PARAMS (arg="myExtractorArg", start=DateTime.Parse("03-08-2010"))) 
WHERE a < 3;
``` 

In both cases, the view is "instantiated" for a given set of parameters. Each time a view is referenced in a script the code in the view is logically executed using the parameters provided in the view instantiation. A view can be used any number of times in a script, and each instantiation can provide a different set of parameters.

<hr>

## Additional Information

- The content of a view file is a single **CREATE VIEW** statement.
- The view body contains any number of SCOPE statements. The rowset yielded by the final (rowset producing) statement in the view body is the rowset returned by the view. If the schema of this rowset does not match the declared schema for the view in the header, it is a compile error.
- **VIEW** definition scripts cannot be compiled independently - they can be only be compiled as a result of being used by a calling script.
- All SCOPE statements in a view definition file must exist within the **CREATE VIEW** statement body. For instance, **#DEFINE**, **#SET**, **RESOURCE**, and **REFERENCE** commands all must be inside the view body.

<hr>

## Example
View Script:
```scala
CREATE VIEW myView
SCHEMA (a:int,
    b:DateTime,
    c:string)
PARAMS (arg string, 
    start DateTime DEFAULT = DateTime.Parse("12-25-1967"))
AS
BEGIN
    REFERENCE "MyAssembly.dll";

    EXTRACT a,b,c FROM "stream" USING MyExtractor(@arg) HAVING b > @start;
END;
```

Main Script:
```scala
//1st approach
relvar = VIEW "myView.script" 
PARAMS (arg="myExtractorArg", start=DateTime.Parse("03-08-2010"));

SELECT a,b,c FROM relvar WHERE a < 3;

//2nd approach
SELECT a,b,c FROM 
(VIEW "myView.script" PARAMS (arg="myExtractorArg", start=DateTime.Parse("03-08-2010"))) 
WHERE a < 3;

//3rd approach
myView =
    VIEW "myView.script" PARAMS (arg="myExtractorArg", start=DateTime.Parse("03-08-2010"));

Report =
    SELECT a,b,c FROM myView;
```

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Core concepts/Extractors and outputters
#Overview

Unstructured streams require an **Extractor** for reading and an **Outputter** for writing. SCOPE includes [**Built-in Extractors**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/Built%2Din-Extractors) and [**Built-in Outputters**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/Built%2Din-Outputters). 

Users can also create their own custom Extractors and Outputters. For a basic example of [**EXTRACT**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT) and [**OUTPUT**](/SCOPE-Language/SCOPE-Language-Reference/OUTPUT-statement) commands, see [Script basics](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Script-basics).

#See also
- [Built-in Extractors and Outputters](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter)
- [CSharp UDO Extractors](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/418/CSharp-UDO-extension)
- [Python UDO Outputters](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/420/Python-UDO-extension)

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/SCOPE script basics
# Overview
To explain how SCOPE works with Cosmos, it's helpful to set up your local machine as a mock "VC" and then run your first script locally. 

Follow these step-by-step instructions:

- [Running your first SCOPE script](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/SCOPE-script-basics/Running-the-first-SCOPE-script)
- [Searchlog sample data](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/SCOPE-script-basics/SearchLog-sample-data)
- [Compile errors](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/SCOPE-script-basics/Compile-errors)
- [Compiling without running a script](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/SCOPE-script-basics/Compiling-without-running-a-script)

**Note:** Visual Studio is not needed in this first tutorial.


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Core concepts/Data types
Native data types
-----------------

SCOPE supports most .NET data types. The full list is shown below:

- **Numeric**: Byte, sbyte, int, uint, long, ulong, float, double, decimal, short, ushort

- **Miscellaneous**: bool, Guid, DateTime, byte[]

- **Text**: char, string

- **Complex**: [MAP<K, V>](/SCOPE-Language/SCOPE-Language-Reference/Data-types/Complex-data-types/MAP<K,-V>), [ARRAY<T>](/SCOPE-Language/SCOPE-Language-Reference/Data-types/Complex-data-types/ARRAY<T>), [STRUCT](/SCOPE-Language/SCOPE-Language-Reference/Data-types/Complex-data-types/STRUCT)

- **Nullables**: bool?, Guid?, DateTime?, byte?, sbyte?, int?, uint?, long?, ulong?, float?, double?, decimal?, short?, ushort?, TimeSpan?


User-defined data types
--------

SCOPE also allows users to create their own [user-defined types](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/User%2Ddefined-types-\(UDTs\)) that can be used for columns in rowsets. For more information, see the section describing [Rowset manipulation](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Rowset-manipulation).

#See also
- [Data types](/SCOPE-Language/SCOPE-Language-Reference/Data-types)


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Rowset manipulation/Selection and filtering rowsets
#Overview
Selection and filtering of rowsets can be used to select specific dates and durations. 

The following selection and filtering code samples are provided:
- [**Code sample 1:** Find all the session dates, durations](#Code-sample-1%3A-Find-all-the-session-dates,-durations)
- [**Code sample 2:** Use the WHERE and HAVING clauses to find all sessions in a region](#Code-sample-2%3A-Use-the-WHERE-and-HAVING-clauses-to-find-all-sessions-in-a-region)
- [**Code sample 3**: Filtering input and output of SELECT statement](#Code-sample-3%3A-Filtering-input-and-output-of-SELECT-statement)
- [**Code sample 4:** Filtering input of the PROCESS](#code-sample-4%3A-filtering-input-of-the-process)
- [**Code sample 5:** Using the AND and OR operator](#code-sample-5%3A-using-the-and-and-or-operator)
- [**Code sample 6:** Find all session occurring between two date with DataTime.Parse()](#code-sample-6%3A-using-datetime.parse())

## Code sample 1: Find all the session dates, durations

```scala
// Find all the session dates, Durations
searchlog = VIEW "/local/Samples/Views/SearchLog.view";

searchlogView =
 SELECT Start, Region, Duration
 FROM searchlog;

OUTPUT searchlogView 
 TO "/local/users/<your alias>/output.txt";
```
##Code sample 2: Use the WHERE and HAVING clauses to find all sessions in a region
The **WHERE** and **HAVING** clauses allow the user to filter data. Logical operators such as **AND** and **OR** are supported.

```scala
// Find all the sessions in the en-gb region
searchlog = VIEW "/local/Samples/Views/SearchLog.view";

searchlogUK =
 SELECT Start, Region, Duration
 FROM searchlog
 WHERE Region == "en-gb";

OUTPUT searchlogUK
 TO "/local/users/<your alias>/output.txt";
```
##Remarks
Notice the use of "==" in the example above instead of "=". This is because expressions in the **SELECT** statement are true C# expressions.

##Code sample 3: Filtering input and output of SELECT statement 
```scala
SELECT RevenueLog.ImpressionID, Clicked, Clicked * PayPerClick AS Pay 
FROM RevenueLog INNER JOIN AdsLog
ON RevenueLog.ImpressionID == AdsLog.ImpressionID
WHERE Clicked > 1 && PayPerClick > 0
HAVING Pay > 10;
```

The example above demonstrates using **WHERE** and **HAVING** to filter the inputs and outputs to a **SELECT** statement respectively. Note the use of the `&&` operator in the predicate expression to **WHERE** - as mentioned above, it is important to understand the operators available in SCOPE Expressions when using **WHERE** and **HAVING**. In the predicate expression for **HAVING**, the column name `Pay` is used, and in the predicate expression for **WHERE** the column name `PayPerClick` and `Clicked` are used. In the case of **HAVING**, the column name `PayPerClick` is not available to use because it does not exist in the output of statement processing. Conversely, in the case of **WHERE**, the column name 'Pay' is not available to use as it is not part of the input to the statement.

##Code sample 4: Filtering input of the PROCESS

This example shows how to use **WHERE** and **HAVING** to filter the input and output Row objects.
```scala
PROCESS q
PRODUCE Query, ClickedUrl1, ClickedUrl2
USING MyProcessor("-a")
WHERE Market != "en_us"
HAVING Query != "google";
```
##Remarks
- Input the RowSet _q_
- Filter the input so that only rows having Market not equal to `en_us` will be input
- Declare that the output schema contains columns `Query`, `ClickedUrl1`, `ClickedUrl2` with types determined by _MyProcessor_
- Use the Processor called `MyProcessor` with the argument "-a" passed in
- Filter the output so that only rows having Query not equal to `google` will be output
 

##Code sample 5: Using the AND and OR operator
The **AND** operator and **OR** operator can be combined with parentheses for more complex expressions.
```scala
// Find all the sessions lasting between 2 and 5 minutes OR that are in the en-gb Region
searchlogFiltered =
 SELECT Start, Region, Duration
 FROM searchlog
 WHERE (Duration >= 2*60 AND Duration <= 5*60) OR (Region == "en-gb");

OUTPUT searchlogFiltered
TO "/local/users/<your alias>/output.txt";
```
##Code sample 6: Using DateTime.Parse()
Because there is no C# literal for the **DateTime** type we have to make use of the **DateTime.Parse()** method as shown below.

```scala
// Find all the sessions occurring between two dates
searchlogFilteredDates =
 SELECT Start, Region, Duration
 FROM searchlog
 WHERE Start >= DateTime.Parse("2012/02/16") AND Start <= DateTime.Parse("2012/02/17");

OUTPUT searchlogFilteredDates 
 TO "/local/users/<your alias>/output.txt";
```


Wiki Page: /SCOPE Language/SCOPE Language Reference/Expressions/Understanding SCOPE expressions
**In this page**
> [Overview](#Overview)
> [SCOPE expression basics](#scope-expression-basics)
> [Supported C# 7.0 features within SCOPE expressions](#supported-c%23-7.0-features-within-scope-expressions)
> [A tip for SQL developers](#a-tip-for-sql-developers)
---

#Overview

An **expression** in a programming language is a combination of _explicit values_, _constants_, _variables_, _operators_, and _functions_ that are interpreted according to the particular rules of precedence and of association for a particular programming language, which computes and then produces another value.

Clauses such as  [**Expressions in SELECT**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/85/Expressions-in-SELECT) and [**WHERE and HAVING**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/375/WHERE-and-HAVING) (and others) allow users to enter SCOPE expressions.

In the [**Expressions in SELECT**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/85/Expressions-in-SELECT) clause to support aggregations, there are special aggregation operators available:

- [**COUNT**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/329/COUNT)
- [**SUM**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/328/SUM)
- [**FIRST**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/1064/FIRST)
- [**LAST**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/1070/LAST)

---

# SCOPE expression basics

A Scope expression is essentially any valid C# expression + some additional SCOPE-defined operators to join those C# expressions.

SCOPE expressions support:

- [Preprocessors](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/302/Preprocessors) syntax using C# inferences and keywords like `AND`, `OR`, `NOT`, `BETWEEN`, `LIKE`, `ANY`, `ALL`, `IF`, or `IN`.
- [Non-preprocessor variables](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3293/Real-variables) or [constant foldable expressions](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/987/Constant-foldable-expressions)

The simplest SCOPE expression is a C# literal. Examples:

- **true**
- **false**
- **"foo"**
- **'c'**
- **34**
- **13.4**

And naturally they can be combined using traditional C# operators to form expressions that resolve to a specific **.Net** type:

- **1 > 2**
- **34.3 \* 10**

Identifiers in the expression come from rowsets:

```scala
rs0 =
    SELECT
        (Score+10) AS NewValue
    FROM Data;
```

OR

```scala
rs0 =
    SELECT
        (data.Score+10) AS NewValue
    FROM Data;
```

As with any C# expression, you can call methods defined on the types:

```scala
rs0 =
    SELECT
        Name.ToUpper() AS NewName
    FROM Data;
```

As with any C# expression, you can call helper methods defined in other assemblies:

```scala
rs0 =
    SELECT
        MyHelper(Name) AS NewName
    FROM Data;
```

Even LINQ and Lambdas are supported. (In the example below assume that Numbers is of type int []. )

```scala
rs0 =
    SELECT
        Numbers.Where( i => i>10 ).First() AS FirstNumberGreaterThanTen
    FROM Data;
```
---

# Supported C# 7.0 features within SCOPE expressions

## Declaration Expression (C#7) 
That is `out <Type> <Variable name>`

```sql
Q = SELECT new STRUCT {{ TryParseSucceeded = double.TryParse(C, out double d), DoubleValue = d }} AS C FROM ...
Q = SELECT C.* FROM Q;
Q = SELECT TryParseSucceeded, DoubleValue FROM Q;
```

## `is` Pattern
That is `<Variable name> is <Type> <New variable name of type Type>`

```sql
Q = SELECT ... WHERE C is MyUDT udt && udt.MyBoolProperty FROM ...; 
```

---

# A tip for SQL developers

Lots of people come to SCOPE from SQL and ask how SCOPE accomplishes things they are familiar with in SQL. The followind details a great example in creating an uppercase string.

A SQL developer will expect to write the following in SCOPE:

```scala
rs1 =
    SELECT
        UPPER( Region ) AS NewRegion
    FROM searchLog;
```

But will be disappointed to find out that SCOPE has no **UPPER()** method. The C# developer knows what to do: just use the string type's intrinsic **ToUpper()** method.

```scala
rs1 =
    SELECT
        Region.ToUpper() AS NewRegion
    FROM searchLog;
```


Wiki Page: /SCOPE Language/SCOPE Language Reference/Expressions/Expressions in SELECT
**In this page**
> [Overview](#overview)  
> [Examples](#examples)  

---
# Overview

Specific columns can be picked for the output rowset using the `SELECT` clause. The `SELECT` clause allows for a range of operations on the data, including renaming columns, type casting, using methods from .NET types, creating new objects, and using user-defined functions. It is important to understand the distinction between the `WHERE` and `HAVING` clauses when filtering data, as `WHERE` operates on input rows and `HAVING` operates on output rows.

---
# Examples
- [Using **AS** keyword](#using-as-keyword)
- [Type casting](#Type-casting)
- [Using .NET types](#Using-.NET-types)
- [Creating new objects with constructors](#Creating-new-objects-with-constructors)
- [Support for Type Initializers](#Support-for-Type-Initializers)
- [Creating .NET collections](#Creating-.NET-collections)
- [CS blocks and user-defined functions](#CS-blocks-and-user-defined-functions)
- [Incorrect usage of **WHERE** and **HAVING**](#Incorrect-usage-of-WHERE-and-HAVING)
- [Correct usage of **HAVING**](#Correct-usage-of-HAVING)
- [Correct usage of **WHERE**](#Correct-usage-of-WHERE)

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span>

## Using AS Keyword

In the example below two columns are retrieved and a third is calculated. Note that when an expression is used to calculate a value, users must assign that column a name via the `AS` keyword.

```scala
renamedColumn =
    SELECT
        Start,
        Region,
        Duration + 1.0 AS Duration2
    FROM searchlog;
```

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span>

## Type casting

Expressions can also be converted to a different type:

```scala
typeCastedColumn =
    SELECT
        Start,
        Region,
        ((double) Duration) AS DurationDouble
    FROM searchlog;
```

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span>

## Using .NET types

Rowset columns are strongly typed. SCOPE allows users to call methods defined on those types in the `SELECT` clause.

```scala
// Find what day of year each session took place

dotnetTypes =
    SELECT Start,
        Region,
        Start.DayOfYear AS StartDayOfYear
    FROM searchlog;
```

---

<span style="float: right; color: green;"><span title="This code has been verified on July 2024"><strong>✓</strong></span> Code Verified - Jul. 2024</span>

## Creating new objects with constructors

Use standard C# expressions to create new objects:

**Scope.script**
```scala
employees =
    SELECT *
    FROM(VALUES ( 1, "Noah" )) AS T(Id: int, Name: string);

objectCreation =
    SELECT
        Id,
        Name,
        new BrowserInfo("Microsoft Edge") AS Browser // Create new object
    FROM employees;

outputRowset =
    SELECT Id,
           Name,
           Browser.Description AS Description
    FROM objectCreation;

OUTPUT outputRowset 
TO "local/users/<your alias>/output.csv";
```

**Scope.script.cs**
```cs
public class BrowserInfo
{
    public string BrowserName { get; set; }
    public string Description { get; set; }

    public BrowserInfo() { }

    public BrowserInfo(string browserName)
    {
        BrowserName = browserName;
        Description = "This employee uses " + browserName + " browser.";
    }
}
```

**Output: [ output.csv ]**
| Id | Name | Description |
| -- | ---- | ----------- |
| 1  | Noah | This employee uses Microsoft Edge browser. |

---

<span style="float: right; color: green;"><span title="This code has been verified on July 2024"><strong>✓</strong></span> Code Verified - Jul. 2024</span>

## Support for Type Initializers

There's even support for using Type Initializers with constructors:

<small>_**Note**: This code sample uses [employees](#scope.script) rowset and [Scope.script.cs](#scope.script.cs) of the previous code sample._</small>

```scala
initializedByContructorColumn  =
    SELECT
        Id,
        Name,
        new BrowserInfo {BrowserName = "Mozilla Firefox"} AS BrowserInfo // Using object initializer
    FROM employees;

outputRowset =
    SELECT Id,
           Name,
           BrowserInfo.BrowserName AS Browser
    FROM initializedByContructorColumn;

OUTPUT outputRowset 
TO "local/users/<your alias>/output.csv";
```

**Output: [ output.csv ]**
| Id | Name | Browser |
| -- | ---- | ------- |
| 1  | Noah | Mozilla Firefox |

---

<span style="float: right; color: green;"><span title="This code has been verified on July 2024"><strong>✓</strong></span> Code Verified - Jul. 2024</span>

## Creating .NET collections

Similar to the ability to create new objects, even collections can be created and initialized. For more information about using complex data types instead of using .NET lists or dictionaries, see [Data types](https://mscosmos.visualstudio.com/ScopeTutorial/_wiki/wikis/ScopeTutorial.wiki/296/Data-types).

```scala
inputData = SELECT * FROM (VALUES (1)) AS T(Id);

createCollections =
    SELECT
        Id,
        new List<int> {1,2,3} AS ListCollection,
        new int[]{1, 2, 3} AS ArrayCollection,
        new []{1, 2, 3} AS UntypedArrayCollection
    FROM inputData;

// Converting the collections to ScopeArray to be able to output them to a Sturctured Stream
outputRowset =
    SELECT 
        Id,
        ARRAY.Create(ListCollection) AS ScopeArrayFromList,
        ARRAY.Create(ArrayCollection) AS ScopeArrayFromArray,
        ARRAY.Create(UntypedArrayCollection) AS ScopeArrayFromUntypedArray
    FROM createCollections;

OUTPUT outputRowset
TO SSTREAM "local/users/<your alias>/output.ss";
```

**Output: [ output.ss ]**
| Id | ScopeArrayFromList | ScopeArrayFromArray | ScopeArrayFromUntypedArray |
| -- | ------------------ | ------------------- | -------------------------- |
| 1  | [1,2,3]            | [1,2,3]             | [1,2,3]                    |

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span>

## CS blocks and user-defined functions

A calculation can be implemented in C# code then later used in an expression. The code can be stored in a separate DLL or as part of a `#CS` block as shown below.

```scala
usingUDFunctions =
    SELECT
        Start,
        Region,
        MyHelper.SecondsToMinutes(Duration) AS DurationInMinutes
    FROM searchlog;

OUTPUT usingUDFunctions 
TO "/local/users/<your alias>/output.txt";

#CS
public static class MyHelper
{
    public static double SecondsToMinutes(int seconds)
    {
        Double minutes = seconds/60.0;
        return minutes;
    }
}
#ENDCS
```
---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span>

## Incorrect usage of WHERE and HAVING

Consider a case in which an expression was used to create a new column:

```scala
filteredSet =
    SELECT
        Start,
        Region,
        Duration/60.0 AS DurationInMinutes
    FROM searchlog
    Where DurationInMinutes >= 20;

OUTPUT filteredSet 
TO "/local/users/<your alias>/output.txt";
```

This doesn't work even though the intention seems very clear. The code above will result in this error:

![image.png](/.attachments/image-7251811e-d435-48ea-913b-cd2f6cc3f495.png)

This is a concrete example of the difference between the `WHERE` and `HAVING` clauses. `DurationInMinutes` is NOT part of the input rows, it is created as part of the output rows. To achieve filtering of these expressions, the `HAVING` clause must be used.

Filtering on Calculated Columns in `SELECT`: `WHERE` vs. `HAVING` Remember that `WHERE` filters input rows, while `HAVING` filters output rows.

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span>

## Correct usage of HAVING

```scala
filteredSet =
    SELECT
        Start,
        Region,
        Duration/60.0 AS DurationInMinutes
    FROM searchlog
    HAVING DurationInMinutes >= 20;
```

Alternatively, a new rowset can be used to achieve the same effect:

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span>

## Correct usage of WHERE

```scala
selectedSet =
    SELECT
        Start,
        Region,
        Duration,
        Duration /60.0 AS DurationInMinutes
    FROM searchlogs;

filteredSet =
    SELECT *
    FROM rs1
    WHERE DurationInMinutes >= 20;
```



Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE
#Overview

SCOPE refers to the compute/query system in Cosmos which includes the SCOPE query language, the SCOPE optimizer, and the SCOPE runtime. The SCOPE Tutorial is focused on providing a framework for understanding the [SCOPE query language](https://mscosmos.visualstudio.com/ScopeTutorial/_wiki/wikis/ScopeTutorial.wiki/286/SCOPE-language-reference). The SCOPE Tutorial covers the basics of batch querying in Cosmos, so users can become familiar with the language while running SCOPE scripts on their machines. 

**Note:** Users _do not_ need access to a Cosmos Virtual Cluster.

The following topics are covered in this section:
- [Core concepts](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts)
- [SCOPE script basics](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/SCOPE-script-basics)
- [Running scripts in the cluster](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Running-scripts-in-the-cluster)
- [Basic rowset manipulation](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Rowset-manipulation)
- [Expressions](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Expressions)
- [Grouping and aggregation](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Grouping-and-aggregation)
- [Splitting and merging rows](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Splitting-and-merging-rows)
- [Sorting](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Sorting)
- [String literals](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/String-literals)
- [Raising Errors and Warnings](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Raising-Errors-and-Warnings)

## SCOPE is not SQL
Although SCOPE queries look similar to SQL queries, SCOPE is a distinct language and many fundamental concepts and syntactic expressions will be very familiar to those with a background in SQL. However, many of the expectations one might have from SQL _do not_ carry over into SCOPE.





Wiki Page: /SCOPE Language/SCOPE Language Reference/Expressions/LINQ and lambdas in expressions
**In this page**
> [Overview](#overview)  
> [Examples](#examples)  

---
# Overview
SCOPE supports **Language-Integrated Query** (LINQ) in expressions, which allows users to write expressive and readable data queries in a manner integrated with .NET languages like C#.

---
# Examples
- [Using Where() to filter a set of Urls](#using-where()-to-filter-a-set-of-urls)
- [Adding a Join](#Adding-a-Join)
- [Anonymous types are not supported](#Anonymous-types-are-not-supported)
- [LINQ query syntax](#LINQ-query-syntax)
- [Using LINQ in preprocessing](#Using-LINQ-in-preprocessing)

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>

## Using Where() to filter a set of Urls

In the example below, the `Where()` `LINQ` extension method is used to filter for a particular set of URLs. `Where()`, like most `LINQ` methods, returns an `IEnumerable<T>` value. Because SCOPE does not support interfaces as column types, the `ToList()` `LINQ` extension method is used to convert it to a collection type that SCOPE does support.

```scala
usingLINQWhere =
    SELECT
        Urls.Split(';').Where(u=> u.StartsWith("http:")).ToList() AS HttpUrls
    FROM searchlog;
```

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>

## Adding a Join

```scala
usingLINQWhere =
    SELECT
        Urls.Split(';').Where(u=> u.StartsWith("http:")).ToList() AS HttpUrls
    FROM searchlog;

usingStringJoin =
    SELECT
        string.Join( ";" , HttpUrls) AS HttpUrls
    FROM usingLINQWhere;
```

> **Note:** 
> - _**DefaultTextOutputter** does not automatically serialize Collection types such as `list<T>`. Users need to convert this back to a type that it supports, such as a string as shown above._
> - _A **REFERENCE** to **System.Linq** is automatically added to a script._


To learn more about what can be expressed in LINQ, consult: [101 LINQ Samples](https://learn.microsoft.com/en-us/samples/dotnet/try-samples/101-linq-samples/).

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>

## Anonymous types are not supported

Creating anonymous types is valid, however it is NOT supported in SCOPE. For example the following script will not work:

```scala
anonymousTypedColumn =
    SELECT
        foo,
        new {a=1, n=2} AS Beer
    FROM data;
```

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>

## LINQ query syntax

The **LINQ Method Syntax** was demonstrated above, but SCOPE also supports the **LINQ Query Syntax**.

```scala
usingLINQquerySyntax =
    SELECT
        (from u in Urls where u.StartsWith("http:")).ToList() AS HttpUrls
    FROM clicks;
```

To learn more go here: [Write LINQ queries - C#](https://learn.microsoft.com/en-us/dotnet/csharp/linq/get-started/write-linq-queries?redirectedfrom=MSDN)

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>

## Using LINQ in preprocessing

For example, the following sample shows how to select the latest available stream within a streamset:

```scala
#DECLARE latestDataGridStream string =
    Enumerable.Range(0, @lookBehindDays + 1)
        .Select(i =>
            string.Format(
                "{0}{1:yyyy}/{1:MM}/DataGridElasticSearch_{1:yyyy}_{1:MM}_{1:dd}.ss",
                @dataGridRoot,
                @StartDate.AddDays(-i)))
        .FirstOrDefault(s => EXISTS(s));
```


Wiki Page: /SCOPE Language/SCOPE Language Reference/Expressions/Order of evaluation for expressions
**In this page**
> [Overview](#Overview)
> [Summary](#summary)  

---
# Overview

**Important:** There's a pattern C# developers are used to, as shown below:

```csharp
if ((QueryString!=null) && (QueryString.StartsWith("bing")))
{
 // do something
}
```

This pattern depends on a C# behavior (common to many languages) called "short-circuiting." Simply put, in the above example, when the code runs there's no logical reason to check both conditions if the first one returns `false`. Short circuiting is useful because evaluating each condition may be expensive. Thus, it is a technique that compilers use to improve the performance of C# code.

When trying to do the same thing in SCOPE, two paths can be picked. Both are valid expressions, but one will cause problems that may not be obvious at first.

**The right choice:** use `&&` to keep the desired short-circuiting behavior

```scala
shortCircuit =
    SELECT *
    FROM data
    WHERE ((Name!=null) && (Name.StartsWith("bing")));
```

**The wrong choice:** use `AND` which does NOT match the short-circuiting behavior

```scala
failedShortCircuit =
    SELECT *
    FROM data
    WHERE ((Name!=null) 
        AND (Name.StartsWith("bing")));
```

The second translation that uses `AND` will **sometimes** fail saying that a **NullReference** has occurred (sometimes it might work on a local box but might fail in the cluster).

The reason is simple and by-design: with `AND`/`OR` SCOPE will try to perform certain optimizations that result in better performance -- for example, it may evaluate the second part of the expression first because it assumes that there is no relationship between the two conditions.

This is a standard optimization technique and the same thing is done in many systems, such as SQL. The gain this optimization provides in performance is well worth the occasional confusion it causes for new SCOPE users -- so this behavior will never change.

---

# Summary 

Use `&&` and `||` if short-circuiting behavior is needed.

As an alternative, SQL-like `ALL`/`ANY` operators are equivalent to `&&`/`||` and can also be used.

**Users CANNOT circumvent the order of evaluation by using multiple statements.**

Users might be tempted to write a script by splitting apart the expression as shown below:

```scala
removingNulls =
    SELECT *
    FROM data
    WHERE Name != null;
```

```scala
stringComparison =
    SELECT *
    FROM removingNulls
    WHERE Name.StartsWith("bing");
```

The assumption here is:

**_First_** a user will get the non-null objects and **then** avoid the null reference issue.

This won't work either. SCOPE is declarative language not an imperative one. Just because rs1 is defined earlier than rs2 in the script above it **does NOT imply** that the `WHERE` condition in rs1 is evaluated before the `WHERE` in rs2. SCOPE reserves the right to combine multiple statements together and perform optimizations. **The `&&` operator must be used to perform short-circuiting.**



Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Expressions
# Overview
An expression in a programming language is a combination of *explicit values*, *constants*, *variables*, *operators*, and *functions* that are interpreted according to the particular rules of precedence and of association for a particular programming language, which computes and then produces another value.

The following topics are covered in this section:
- [Understanding SCOPE expressions](/SCOPE-Language/SCOPE-Language-Reference/Expressions/Understanding-SCOPE-expressions)
- [Expressions in SELECT](/SCOPE-Language/SCOPE-Language-Reference/Expressions/Expressions-in-SELECT)
- [LINQ and lambdas in expressions](/SCOPE-Language/SCOPE-Language-Reference/Expressions/LINQ-and-lambdas-in-expressions)
- [Order of evaluation for expressions](/SCOPE-Language/SCOPE-Language-Reference/Expressions/Order-of-evaluation-for-expressions)
- [Logical operators in expressions](/SCOPE-Language/SCOPE-Language-Reference/Expressions/Logical-operators-in-expressions)
- [Regular expressions](/SCOPE-Language/SCOPE-Language-Reference/Expressions/Regular-expressions)

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Rowset manipulation/Picking specific columns in rows
#Overview
Picking specific columns in rows is also possible.
##Code sample
```scala
region =
 SELECT
 Region
 FROM searchlog;
```
##Data
| Region |
| -------|
| en_ca |
| en_ch |
| en_fr |
| en_gb |
| en_gr |
| en_mx |
| en_ux |



Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Grouping and aggregation
# Overview

Grouping collapses multiple rows into single rows based on some criteria. In combination with performing a grouping operation, some fields in the output rowset must be aggregated into a meaningful value (or discarded if no possible or meaningful aggregation can be done).

The following topics are covered in this section:
- [Data types coming from aggregates](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Grouping-and-aggregation/Data-types-coming-from-aggregates)
- [DISTINCT with aggregates](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Grouping-and-aggregation/DISTINCT-with-aggregates)

<br><hr>
#Code Samples

The following grouping and aggregation code samples are also included:
- [Code sample 1: List all session durations](#Code-sample-1%3A-List-all-session-durations)
- [Code sample 2: Total duration of all sessions combined](#Code-sample-2%3A-Total-duration-of-all-sessions-combined)
- [Code sample 3: Find total duration by Region](#Code-sample-3%3A-Find-total-duration-by-Region)
- [Code sample 4: Find all the Regions where the total dwell time is > 200](#Code-sample-4%3A-Find-all-the-Regions-where-the-total-dwell-time-is->-200)
- [Code sample 5: Group total number of sessions](#Code-sample-5%3A-Group-total-number-of-sessions)
- [Code sample 6: Count the number of total session by Region](#code-sample-6%3A-count-the-number-of-total-sessions-by-region)
- [Code sample 7: Count the number of sessions by Region and include duration for that language](#Code-sample-7%3A-Count-the-number-of-sessions-by-Region-and-include-duration-for-that-language)

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span>

**Input:**

```scala
searchlog = 
    EXTRACT ImpressionId : int,
            UserId : int, 
            Start : DateTime, 
            Region : string, 
            Query : string, 
            Duration : int, 
            ClickedUrls  : string, 
            Urls  : string
    FROM @"/local/Samples/SearchLog/SearchLog.txt"
    USING DefaultTextExtractor();
```

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span>

##Code sample 1: List all session durations
This behavior can be accomplished by building up to it in stages.
```scala
// list all session durations.
ListDuration=
    SELECT
        Duration
    FROM searchlog;

OUTPUT ListDuration
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```
The code above creates a simple list of integers.

| **Duration**                             |
|------------------------------------------|
| 73                                       |
| 614                                      |
| 74                                       |
| 24                                       |
| 1213                                     |
| 241                                      |
| 502                                      |
| 60                                       |
| 1270                                     |
| 610                                      |
| 422                                      |
| 283                                      |
| 305                                      |
| 10                                       |
| 612                                      |
| 1220                                     |
| 691                                      |
| 63                                       |
| 30                                       |
| 119                                      |
| 732                                      |
| 183                                      |
| 630                                      |

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span>

##Code sample 2: Total duration of all sessions combined
Add all the numbers together to yield a rowset with exactly one row and one column.

```scala
// Find the total duration for all sessions combined
totalDuration =
    SELECT
        SUM(Duration) AS TotalDuration
    FROM searchlog;

OUTPUT totalDuration 
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```

| **TotalDuration** |
| ---------------|
| 9981           |

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span>

##Code sample 3: Find total duration by Region
Use the **GROUP BY** operator to break apart the totals by Region.

```scala
// find the total Duration by Region
totalDurationByRegion =
    SELECT
        Region,
        SUM(Duration) AS TotalDuration
    FROM searchlog
    GROUP BY Region;

OUTPUT totalDurationByRegion
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```

| **Region** | **TotalDuration**|
|--------|------|
| en\_ca | 24   |
| en\_ch | 10   |
| en\_fr | 241  |
| en\_gb | 688  |
| en\_gr | 305  |
| en\_mx | 422  |
| en\_us | 8291 |

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span>

##Code sample 4: Find all the Regions where the total dwell time is > 200
Users can utilize the **HAVING** operator to restrict the output rowset to the rows that have aggregate values they may be interested in. For example, a user may want to find all the _Regions_ where total dwell time is above some value.

```scala
// find all the Regions where the total dwell time is > 200
totalDurationByRegionFiltered =
    SELECT
        Region,
        SUM(Duration) AS TotalDuration
    FROM searchlog
    GROUP BY Region
    HAVING TotalDuration > 200;

OUTPUT totalDurationByRegionFiltered
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```

| **Region** | **TotalDuration** |
|--------|------|
| en\-fr | 241  |
| en\-gb | 688  |
| en\-gr | 305  |
| en\-mx | 422  |
| en\-us | 8291 |


<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span>

##Code sample 5: Group total number of sessions
This example shows how to group the number of total sessions.
```scala
// group the number of total sessions.
totalSessions =
    SELECT
    COUNT() AS NumSessions
    FROM searchlog;

OUTPUT totalSessions
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```
| **NumSessions** |
| ----------- |
| 23 |

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span>


##Code sample 6: Count the number of total sessions by Region
This example shows how to count the number of total sessions by _Region_.

```scala
//find the number of Sessions by Region
totalSessionsByRegion =
    SELECT
        COUNT() AS NumSessions,
        Region
    FROM searchlog
    GROUP BY Region;

OUTPUT totalSessionsByRegion
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```

| **NumSessions** | **Region** |
|----|--------|
| 1  | en\_ca |
| 1  | en\_ch |
| 1  | en\_fr |
| 2  | en\_gb |
| 1  | en\_gr |
| 1  | en\_mx |
| 16 | en\_us |

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span>

##Code sample 7: Count the number of sessions by Region and include duration for that language
This example shows how to count the number of total sessions by _Region_ and include total duration for that language.

```scala
//Find number of sessions, total, average, min and max duration per Region
totalSessionsAgg = 
    SELECT
        COUNT() AS NumSessions,
        Region,
        SUM(Duration) AS TotalDuration,
        AVG(Duration) AS AvgDwellTtime,
        MAX(Duration) AS MaxDuration,
        MIN(Duration) AS MinDuration
    FROM searchlog
    GROUP BY Region;

OUTPUT totalSessionsAgg
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```


| **NumSessions:long** | **Region** | **TotalDuration:long** | **AvgDuration:double?** | **MaxDuration:int** | **MinDuration:int** |
|------------------|--------|--------------------|---------------------|-----------------|-----------------|
| 1                | en\_ca | 24                 | 24                  | 24              | 24              |
| 1                | en\_ch | 10                 | 10                  | 10              | 10              |
| 1                | en\_fr | 241                | 241                 | 241             | 241             |
| 2                | en\_gb | 688                | 344                 | 614             | 74              |
| 1                | en\_gr | 305                | 305                 | 305             | 305             |
| 1                | en\_mx | 422                | 422                 | 422             | 422             |
| 16               | en\_us | 8291               | 518\.1875           | 1270            | 30              |



Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/System-defined aggregates
# Overview

SCOPE system-defined aggregates (i.e. [_built-in aggregate functions_](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions)) include several common aggregation functions:

- [**ANY_VALUE**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/ANY_VALUE)
- [**ARGMAX**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/ARGMAX)
- [**AVG**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/AVG)
- [**COUNT**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/COUNT)
- [**COUNTIF**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/COUNTIF)
- [**FIRST**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/FIRST)
- [**­­LAST**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/LAST)
- [**LIST**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/LIST)
- [**MAX**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/MAX)
- [**MIN**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/MIN)
- **[STDEV *](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/STDEV)**

#Code Samples
The following system-defined aggregate code samples are provided:
- [Code sample 1: Getting a value with ANY_VALUE and FIRST](#Code-sample-1%3A-Getting-a-value-with-ANY_VALUE-and-FIRST)
- [Code sample 2: Getting a value with FIRST](#Code-sample-2%3A-Getting-a-value-with-FIRST)
- [Code sample 3: Conditionally counting with COUNT](#Code-sample-3%3A-Conditionally-counting-with-COUNT)
- [Code sample 4: Comparing counts with COUNTIF](#Code-sample-4%3A-Comparing-counts-with-COUNTIF)
- [Code sample 5: Using the ARGMAX function](#Code-sample-5%3A-Using-the-ARGMAX-function)


##Code sample 1: Getting a value with ANY_VALUE and FIRST

**ANY_VALUE** gets a value for a column with no implications about where the value came from inside that rowset. It could be the first value, the last value, or any value in between. It is useful in some scenarios where the user doesn't care which value they receive as long as they get one.

```scala
AnyValueStart =
 SELECT
 ANY_VALUE(Start) AS FirstStart,
 Region
 FROM searchlog
 GROUP BY Region;
```

###Remarks
Since **FIRST** is not named well, it does NOT guarantee the first value in a rowset will be received. Instead it behaves exactly like **ANY_VALUE**. Avoid using **FIRST**, instead use **ANY_VALUE**.

##Code sample 2: Getting a value with FIRST
```scala
FirstStart =
 SELECT
 FIRST(Start) AS FirstStart,
 Region
 FROM searchlog
 GROUP BY Region;
```

###Remarks
There is one key difference between **ANY_VALUE** and **FIRST**: **ANY_VALUE** on some type T will return T? _while_ **FIRST** on some type T will return T.

##Code sample 3: Conditionally counting with COUNT

The following example shows how to count the total sessions per Region:
```scala
SessionsPerRegion =
 SELECT
 Region,
 COUNT() AS NumSessions
 FROM searchlog
 GROUP BY Region;
```
##Code sample 4: Comparing counts with COUNTIF
To compare the total count with the count of sessions that had a large dwell time, more than 600 seconds, use **COUNTIF**.

```scala
LongSessionsPerRegion =
 SELECT
 Region,
 COUNT() AS NumSessions,
 COUNTIF( Duration > 600 ) AS NumLongSessions
 FROM searchlog
 GROUP BY Region;
```

| **Region** | **NumSessions** | **NumLongSessions:long** |
|--------|------------------|----------------------|
| en\-ca | 1                | 0                    |
| en\-ch | 1                | 0                    |
| en\-fr | 1                | 0                    |
| en\-gb | 2                | 1                    |
| en\-gr | 1                | 0                    |
| en\-mx | 1                | 0                    |
| en\-us | 16               | 8                    |


##Code sample 5: Using the ARGMAX function

The **ARGMAX** function is simple:

**ARGMAX(a, b)** = Find the row with the maximum value for column a, from that row return the value for b.

Imagine we have some employee data (You can find the data sample in [Cosmos Samples](https://mscosmos.visualstudio.com/DefaultCollection/_git/CosmosSamples?path=/VCROOT/local/Samples/SampleData)):

| **FirstName** | **LastName** | **Tenure** | **Title**     | **Department**  |
|-----------|----------|------------|-----------|-------------|
| Joe       | Smith    | 3897       | Paralegal | Legal       |
| Sally     | Johnson  | 8897       | CFO       | Exec        |
| Trent     | Michaels | 43         | Intern    | Engineering |
| Joshua    | Phillips | 373        | Developer | Engineering |
| Alice     | Edwards  | 513        | Tester    | Engineering |


What's the last name of the employee who has the longest tenure? This is simply answered with **ARGMAX**.

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>✓</strong></span> Code Verified - June 2024</span></span><br>
```scala
Tenures =
 EXTRACT
 FirstName:string,
 LastName:string,
 Tenure:int,
 Title:string,
 Department:string
 FROM "/local/users/<your alias>/SampleData/tenures.tsv"
 USING DefaultTextExtractor();

MostTenuredEmployee =
 SELECT
 ARGMAX( Tenure, LastName ) AS MostTentured
 FROM Tenures;

OUTPUT MostTenuredEmployee 
    TO "/local/users/<your-alias>/output.txt" 
    USING DefaultTextOutputter();
```

 **OUTPUT MostTenuredEmployee** will return the following data:

|**MostTenured**|
|-----------|
| Johnson   |


**ARGMAX** like all the other aggregates works with **GROUP BY** letting us find the most tenured employee by department.

```scala
MostTenuredEmpbyDept =
 SELECT
 Department,
 ARGMAX( Tenure, LastName ) AS MostTentured
 GROUP BY Department
 FROM Tenures;
```
| **Department**  | **MostTentured** |
|-------------|--------------|
| Engineering | Edwards      |
| Exec        | Johnson      |
| Legal       | Smith        |


```SCALA
MostTenuredbyDept =
 SELECT
 Department,
 ARGMAX( Tenure, LastName ) AS MostTenured,
 ARGMAX( Tenure, Tenure ) AS Tenure
 GROUP BY Department
 FROM Tenures;
```

| **Department**  | **MostTenured** | **Tenure** |
|-------------|-------------|------------|
| Engineering | Edwards     | 513        |
| Exec        | Johnson     | 8897       |
| Legal       | Smith       | 3897       |


**Protip:** Instead of **ARGMAX**, use the **ROW_NUMBER()** and **DENSE_RANK()** Ranking functions ([Windowing](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/SELECT/Windowing)). 

##An Important fact about VAR and STDEV

For the Statisticians, variance (**VAR**) and standard deviation (**STDEV**) are the **sample version** with Bessel's correction, **not** the better-known **population version**.

Wiki Page: /SCOPE Language/SCOPE Language Reference/Expressions/Regular expressions
**In this page**
> [Overview](#Overview)
> [Examples](#Examples)

---
# Overview

Regular expressions provide advanced text matching capabilities in a terse specification. Regular expressions are supported in the [**WHERE** and **HAVING**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/375/WHERE-and-HAVING) clauses.

---
# Examples
- [Finding simple patterns](#finding-simple-patterns)
- [Extracting a REGEX match](#extracting-a-regex-match)

---
<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>

## Finding simple patterns

```scala
// Find all the sessions where the Query contained the word pizza (but not pizzeria, for example)

patternFindingFilter =
    SELECT
        Start,
        Region,
        Duration
    FROM Searchlog
    WHERE REGEX(@"\bpizza.*\b").IsMatch(Query);

OUTPUT patternFindingFilter 
TO "/local/users/<your alias>/output.txt";
```

---

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>

## Extracting a REGEX match

Sometimes users need to "pull" out a substring and promote that to a column.

For example, if there is a column called Name and its value can look like **"--------Cosmos01------"**, **"foooCosmos11bar,"** etc. and we want to pull out the **"Cosmos<number>"** parts, then REGEX and SCOPE make this pretty easy to do.

```scala
patternMatchingValue =
    SELECT
        Name,
        REGEX(@"Cosmos[0-9]*").Match(name).Value AS cosmosCluster
    FROM Data;
```

> **Note:** _That the above example is case-sensitive, so it won't match "cosmos08" but will match "Cosmos08"._



Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Rowset manipulation/Single row rowsets
#Overview
Understanding alternative ways to use rowsets is also helpful when coding SCOPE scripts.

<br><hr>

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>✓</strong></span> Code Verified - June 2024</span></span>

## Code sample 1: Users cannot extract a single scalar value from a rowset (Incorrect)
This is a common issue for users new to SCOPE. Often, they want to store a value from a rowset in a scalar value. For example, they may want the **MAX** for a column in a rowset, but also want to re-use that value for something else, and will try to write code like this:

**Script:**
```scala
data = 
    SELECT * 
    FROM (VALUES
        (79.99, "Monitor"),
        (89.99, "Printer"),
        (99.99, "Toy Car"),
        (109.99, "Drone")
    ) AS data(Cost, Item);

maxcost =
    SELECT 
        MAX(Cost) AS MaxCost
    FROM data;

OUTPUT maxcost
TO SSTREAM @"/output/<your-alias>/maxcost.ss";
```

**Output:**
| MaxCost |
| ------- |
| 109.99  |

There’s nothing wrong with this syntactically – it will compile. However, maxcost will not be a double, it will be a rowset with a single row and a single column called **MaxCost**.

There is no way in SCOPE to return a single scalar value like this. The alternative is to get a one-row rowset and then combine (**JOIN**) that with another rowset to achieve the wanted computation.

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>✓</strong></span> Code Verified - June 2024</span></span>
##Code sample 2: Using a single row rowset

**Script:**
```scala
maxcost =
    SELECT 
        MAX(Cost) AS MaxCost
    FROM data;

differenceFromMax =
   SELECT Item,
          Cost, 
          MaxCost - Cost AS Difference
   FROM data
   CROSS JOIN maxcost;

OUTPUT differenceFromMax 
TO SSTREAM @"/output/<your-alias>/differenceFromMax.ss";
```

**Output:**
| Item       | Cost  | Difference |
|------------|-------|------------|
| Monitor    | 79.99 | 30.00      |
| Printer    | 89.99 | 20.00      |
| Toy Car    | 99.99 | 10.00      |
| Drone      | 109.99| 0.00       |

<br><hr>

#See also
- [CROSS JOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/CROSS-JOIN)

Wiki Page: /SCOPE Language/SCOPE Language Reference/Expressions/Logical operators in expressions

# Overview
The C# logical operators: `||`, `&&`, and `!`

To make it more straightforward for SQL developers, the equivalents to the C# logical operators are supported as shown below:


|      | **C#** | **SQL** |
|------|----|-----|
| Logical AND with short-circuiting | `(a && b && c)`   | `ALL( a, b, c)` |
| Logical OR with short-circuiting |  `(a || b || c)`   | `ANY( a, b, c)` |
| Logical NOT | `!a` | `NOT(a)` |

It's preferred that developers use C# expressions over the SQL style.

---

## How to Engage, Contribute, and Provide Feedback

- Use [MS Stack Overflow](https://stackoverflow.microsoft.com/questions/ask?tags=scope,cosmos) for basic Cosmos questions. Tag your questions with "scope", "cosmos" or both. (Tags are watched by the Cosmos Team)
- Or send an email to scope@microsoft.com for general inquiry and support.
- For general Cosmos email discussion and community support, join the [Cosmos Discussion Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join the [Cosmos Announcements Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Information can be found here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---

## See also
- [Logical conditional operators](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/Logical-conditional-operators)
- [Order of evaluation for expressions](/SCOPE-Language/SCOPE-Language-Reference/Expressions/Order-of-evaluation-for-expressions)

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Rowset manipulation/TOP N Rows
# Overview
## Getting exactly N Rows or the TOP N based on a column


The **TOP** operator can be used to limit the number of rows:

```scala
Top5SearlogsUnordered =
 SELECT TOP 5
 Region,
 Duration
 FROM searchlog;
```

Without an [**ORDER BY**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/364/ORDER-BY) clause, the above statement is simply fetching *any* 5 rows it can. This is often not what the user wants. Instead, add an **ORDER BY** on some fields as shown below.

```scala
Top5SearlogsOrdered =
 SELECT TOP 5
 Region,
 Duration
 FROM searchlog
 ORDER BY Duration DESC;
```


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Sorting
#Overview

Rowsets can be sorted by using the [**ORDER BY**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/364/ORDER-BY) operator and should include an **[OUTPUT](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/413/OUTPUT-statement)** statement specifying the location to output, specifying the **ASC** and **DESC** keyword controls whether the sort is ascending or descending order.

**Note:** Sorting should always include a comment on the maximum number of rows supported.
##Syntax
```scala
// List the sessions in increasing order of Duration
SearchLogDurationLowesttoHighest =
 SELECT
 Start,
 Region,
 Duration
 FROM searchlog
 ORDER BY Duration ASC;

OUTPUT SearchLogDurationLowesttoHighest
TO "/local/users/<your alias>/SearchLogDurationLowesttoHighest.txt";
```

```scala
// List the sessions in decreasing order of Duration
SearchLogHighesttoLowest =
 SELECT
 Start,
 Region,
 Duration
 FROM searchlog
 ORDER BY Duration DESC;

OUTPUT SearchLogHighesttoLowest
TO "/local/users/<your alias>/SearchLogHighesttoLowest.txt";
```




Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Splitting and merging rows
#Overview
Splitting and merging rows can be accomplished using the **CROSS APPLY**, **LIST**, **MAP_AGG,** **ARRAY_AGG** functions:
- [Split row with **CROSS APPLY**](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Splitting-and-merging-rows/Split-rows-with-CROSS-APPLY)
- [**CROSS APPLY** with multiple columns](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Splitting-and-merging-rows/CROSS-APPLY-with-multiple-columns)
- [Merge rows with **LIST**](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Splitting-and-merging-rows/Merge-rows-with-LIST)
- [Merge rows with **ARRAY_AGG**](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Splitting-and-merging-rows/Merge-rows-with-ARRAY_AGG)


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Splitting and merging rows/Split rows with CROSS APPLY
# Overview

The following examples provide insight into how to use the **CROSS APPLY** operator to split rows:
- [Code sample 1: Searchlog](#Code-sample-1%3A-Searchlog)
- [Code sample 2: Using the **CROSS APPLY** operator](#code-sample-2%3A-using-the-**cross-apply**-operator)
- [Code sample 3: Using *-operator-with-a-column-with a TupleList, which contains a list of tuples (Advanced)](#Code-sample-3%3A-Using-*-operator-with-a-column-with-a-TupleList,-which-contains-a-list-of-tuples-(Advanced))



##Code sample 1: Searchlog
```scala
regionUrls =
 SELECT
 Region,
 Urls
 FROM searchlog;
```

The query above returns something like this:

| **Region** | **Urls**  |
|--------|-------|
| en\-us | A;B;C |
| en\-gb | D;E;F |


The **Urls** column contains strings, but each string is a semicolon-separated list of URLs. To break apart the **Urls** field so that only one URL is present on every row, use **CROSS APPLY**. For example, below is what we want to see:

| **Region** | **Url** |
|--------|------|
| en\-us | A    |
| en\-us | B    |
| en\-us | C    |
| en\-gb | D    |
| en\-gb | E    |
| en\-gb | F    |


##Code sample 2: Using the **CROSS APPLY** operator

```scala
regionUrls  =
 SELECT
 Region,
 Urls
 FROM searchlog;

regionUrlsSplit =
 SELECT
 Region,
 SplitUrls AS Url
 FROM regionUrls 
 CROSS APPLY Urls.Split(';') AS SplitUrls;
```

**Note:** The transformation above is possible to perform programmatically with **Processors** -- but **CROSS APPLY** is always preferred to custom processors.

##Code sample 3: Using * operator with a column with a TupleList, which contains a list of tuples (Advanced)
```scala
regionUrlTup = 
    SELECT *, Tup // This is incorrect, and will give an error on Tup having multiple aliases in the selection
    FROM searchlog
        CROSS APPLY Regions.Split(';').Zip(Urls.Split(';'), Tuple.Create) AS Tup;

regionUrlTup = 
    SELECT * // This is correct, but will include both TupleList and Tup. The duplication of TupleList probably isn’t desired. Also, you will need a custom outputter for the Tuple.
    FROM searchlog
        CROSS APPLY Regions.Split(';').Zip(Urls.Split(';'), Tuple.Create) AS Tup;

regionUrlTup = 
    SELECT *.Except(Regions, Urls) // Correct, includes Tup as a tuple in the output rowset
    FROM searchlog
        CROSS APPLY Regions.Split(';').Zip(Urls.Split(';'), Tuple.Create) AS Tup;// TupleList is still available in the input, so it can be cross applied here

regionUrlTup =
   SELECT *.Except(Regions, Urls, Tup), // Correct, excludes both TupleList and Tup in the output rowset
                 Tup.Item1 AS Region, // Tup is available to dereference when constructing the rowset
                 Tup.Item2 AS Url
   FROM searchlog
   CROSS APPLY Regions.Split(';').Zip(Urls.Split(';'), Tuple.Create) AS Tup;
```

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Splitting and merging rows/CROSS APPLY with multiple columns
# Overview

Occasionally users may find data organized in the manner shown below:

| **Regions**              | **Urls**  |
|----------------------|-------|
| en\-us;en\-us;en\-us | A;B;C |
| en\-gb;en\-gb;en\-gb | D;E;F |


In this structure, each value in the **Regions** column is a set of values that correspond 1-to-1 with a value in the **Urls** column.

Users should "zip" the pairs of values together to return this data:


| **Region** | **Result** |
|--------|--------|
| en\-us | A      |
| en\-us | B      |
| en\-us | C      |
| en\-gb | D      |
| en\-gb | E      |
| en\-gb | F      |
##Code sample: CROSS APPLY with multiple columns

```scala
regionUrl= 
    SELECT 
        Tup.Item1 AS Region, 
        Tup.Item2 AS Result
    FROM rs0
        CROSS APPLY Regions.Split(';').Zip(Urls.Split(';'), Tuple.Create) AS Tup;
```
<hr>

##Code sample: CROSS APPLY with more than 2 columns
For example, we have the following input rowset:
| **Regions**              | **Urls**  |**PostalCode**|
|----------------------|-------|-|
| en\-us;en\-us;en\-us | A;B;C |68001;98001;20101|
| en\-gb;en\-gb;en\-gb | D;E;F |11269;00040;54490|


And would like to utilize CROSS APPLY to correspond 1-to-1 correspondence for each of the values.
```scala
rawdata = SELECT *  
               FROM (VALUES   
                      ("en-us;en-us;en-us","A;B;C","68001;98001;20101")  
                    , ("en-gb;en-gb;en-gb", "D;E;F","11269;00040;54490")  
                 ) AS rawdata (Region, Urls, PostalCode);


regionUrlPostalCode =
    SELECT tup.Item1 AS Region,
           tup.Item2 AS Urls,
           tup.Item3 AS PostalCode
    FROM rawdata
         CROSS APPLY Region.Split(';').Zip(Urls.Split(';'), Tuple.Create).Zip(PostalCode.Split(';'), (t, d) => Tuple.Create(t.Item1, t.Item2, d)) AS tup;
OUTPUT regionUrlPostalCode
TO SSTREAM @"/Output/regionUrlPostalCode.ss";
```

This will ouput the following data:
| **Regions**          | **Urls**|**PostalCode**|
|----------------------|-------|-|
|en-us|A|68001|
|en-us|B|98001|
|en-us|C|20101|
|en-gb|D|11269|
|en-gb|E|40|
|en-gb|F|54490|



---
#See Also
 - [CROSS APPLY](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/1010/CROSS-APPLY)
 - [Merge rows with ARRAY_AGG](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Splitting-and-merging-rows/Merge-rows-with-ARRAY_AGG)
- [Merge rows with LIST](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Splitting-and-merging-rows/Merge-rows-with-LIST)

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Splitting and merging rows/Merge rows with LIST
#Overview

The **LIST** multiple columns aggregate operator performs the opposite of **CROSS APPLY**.

For example, if this is the starting data:


| **Region** | **Result** |
|--------|--------|
| en\-us | A      |
| en\-us | B      |
| en\-us | C      |
| en\-gb | D      |
| en\-gb | E      |
| en\-gb | F      |


But the data below is the wanted output:


| **Region** | **Urls**  |
|--------|-------|
| en\-us | A;B;C |
| en\-gb | D;E;F |


##Code sample: Using the LIST operator to merge rows
In the example below, the rowset _SearchLogURLSplit_ is taken apart by **CROSS APPLY** and then reconstructed as rowset _SearchLogURLMerge_ via the **LIST** operator.

```scala
SearchlogRowset = 
    SELECT 
        Region, 
        Urls
    FROM searchlog;

SearchLogURLSplit = 
    SELECT 
        Region, 
        SplitUrls AS Url
    FROM  SearchlogRowset
    CROSS APPLY Urls.Split(';') AS SplitUrls;

SearchLogURLMerge = 
    SELECT 
        Region, 
        String.Join(";" , LIST(Url).ToArray() ) AS Urls
    FROM SearchLogURLSplit
    GROUP BY Region;

```


**Protip:** **LIST** offers no guarantees on order.  So a user could end up with _C;A;B_, for example, for _en-us_.

In general, Cosmos treats data homogenously with no respect for order unless explicit ordering instructions are provided.  This should be kept in mind if a user is relying on order.






Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Splitting and merging rows/Merge rows with ARRAY_AGG
# Overview
[**ARRAY_AGG**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/ARRAY_AGG) works a lot like [**LIST**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/LIST) but is the preferred way for merging lists of column values.
##Code sample: Using ARRAY_AGG to merge lists of column values

```scala
SearchlogRowset = 
    SELECT 
        Region, 
        Urls
    FROM searchlog;

SearchLogURLSplit = 
    SELECT 
        Region, 
        SplitUrls AS Url
    FROM  SearchlogRowset
    CROSS APPLY Urls.Split(';') AS SplitUrls;

SearchLogURLMerge = 
    SELECT 
        Region, 
        string.Join(";" , ARRAY_AGG(Url) ) AS Urls
    FROM SearchLogURLSplit
    GROUP BY Region;
```


## ARRAY_AGG versus LIST
Generally, it's better to choose **ARRAY_AGG** over **LIST** because it is more efficient and more optimizable. 

The functional difference between **ARRAY_AGG** and **LIST** is:
- **LIST** can handle *any* type
- **ARRAY_AGG** can handle only the [native SCOPE types](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Data-types).

## ARRAY_AGG versus Array<T> and List<T>

**Array<T>** and **List<T>** are collections from the System.Collections namespace. They can be used in SCOPE, but users should always choose **ARRAY_AGG** if possible, because it is more efficient and more optimizable than using the standard .Net collection types.



Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/String literals
#Overview

SCOPE uses different kinds of string literals:

- The regular C# string literal

- The verbatim C# string literal -- these string literals begin with an @ character

Either can be used in SCOPE. The key differences are in the handling of embedded quotation marks, backslashes, and newlines as shown in the table below:

|        String type         | Regular              |Verbatim                 |
|-----------------|----------------------|-------------------------|
| Simple string   | "Foo"                | @"Foo"                  |
| Quotation marks | "\\"Hello\\" I said" | @"""Hello"" I said"     |
| Slashes         | "a/b/c"              | @"a/b/c"                |
| Backslashes     | "a\\\\b\\\\c"        | @"a\\b\\c"              |


newlines        
`"a\\r\\nb\\r\\nc"     `
```
@"a
b
c
```


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/SCOPE script basics/Compiling without running a script

#Overview

To verify that the SCOPE script will compile correctly, check the syntax to make sure the command looks like the following:

```
c:\scopesdk\scope.exe compile -i test.script *<Add the other parameters here>*
```

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/SCOPE script basics/Compile errors
#Overview

The following shows an example of an **unsuccessful** compile: 

**Note:** In the script below, the semicolon has been removed by commenting it out.

```scala
rs0 = EXTRACT
 FirstName : string,
 LastName : string,
 Age : int
 FROM
 "/local/users/v-merkoz/SampleData/test_input.tsv"
 USING DefaultTextExtractor() **// ;**
OUTPUT rs0
 TO "/local/users/v-merkoz/output.tsv"
   USING DefaultTextOutputter();

```

The result will be long, but scrolling down will reveal the details of interest.
![image.png](/.attachments/image-fbaa686f-82a0-47b8-be92-20f63e7a5c43.png)

**Remarks**

- See the error code: **E_CSC_USER_SYNTAXERROR.**
- The **USER** part of **E_CSC_USER_SYNTAXERROR** indicates that the source of the error is the script written by the user -- in other words, the script has bad code and it is the user's fault.
- The **###** sequence is used to draw the user's attention to the point in the script with the error. Syntax Errors will generally use ###. Other errors may not be able to pinpoint the error this way.
- These syntax errors happen when the script is compiled -- this compilation failed and the script never started running.

---
## Backtick (`) token is Reserved

Using backtick token in SCOPE script will raise a compilation error. 

### Code sample
``` cs
FROM (SSTREAM SPARSE STREAMSET @DataLogsInput`  
            PATTERN "%Y/%m/%d/channelmessages_%Y_%m_%d.ss" 
            RANGE __date = [@FirstStartDate, @FirstEndDate]) 
```

### Error
``` cs
E_CSC_USER_SYNTAXERROR:  
syntax error. Expected one of: _ELSEIF _ELSE _ENDIF 
Invalid syntax found in the script. 
```

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/SCOPE script basics/Running the first SCOPE script
# Overview


Follow these step-by-step instructions to run your first SCOPE script locally:
- [Download the **SCOPE SDK** and the **CosmosSamples**](#Download-the-SCOPE-SDK-and-CosmosSamples)
- [Run your first SCOPE script](#run-your-first-SCOPE-script)

Visual Studio is not needed in this first tutorial. However, you can also use Scope Studio for this exercise if you have it ready. Refer to [SCOPE Studio](/Cosmos-Tools-and-SDKs/SCOPE-Studio) for more information.


**Unblocking the bits**
When you download both ZIP files and unzip the contents, you may notice that the EXEs and files are blocked from running or being used, which is a security feature of Internet Explorer. **This may cause SCOPE.exe to fail to start or it may fail when compiling a script.**

   **To unblock the bits** 
Right-click on the ZIP file and select **Properties**. Then click on **Unblock**. Once the ZIP is unblocked then extract the contents.

## Download the SCOPE SDK and CosmosSamples



1. Download the latest SCOPE SDK:
http://aka.ms/SCOPESDK
2. Extract to the `C:\SCOPESDK` folder.


3. Download the Cosmos Samples: <https://mscosmos.visualstudio.com/DefaultCollection/_git/CosmosSamples>

4. From the **CosmosSamples** menu, click on **... > Download as Zip.**

![image.png](/.attachments/image-7bda4705-b4fb-4951-a479-41f901805e56.png)

5. Move the **CosmosSamples.zip** files to the root of your **SCOPESDK** (For example, `C:\SCOPESDK\CosmosSamples`)

6. Right-click on the zip file and select **Extract All...**




The following folders are created in the root of the downloaded folder:

- **ScopeSDK** - where the SCOPE compiler and related binaries are stored.
- **VCROOT** - use the **VCROOT** folder to represent the root path of a "vc" running on our machine.
##Run your first SCOPE script

1. Open Notepad and copy and paste the following code in an untitled file: 
```scala
searchlog =
    EXTRACT ImpressionId : int,
	    UserId : int,
            Start : DateTime,
            Region : string,
            Query : string,
            Duration : int,
            Urls : string,
            ClickedUrls : string
    FROM @"/CosmosSamples/VCROOT/local/Samples/SearchLog/SearchLog.txt"
    USING DefaultTextExtractor();

OUTPUT searchlog
   TO @"/CosmosSamples/VCROOT/local/users/alias/output.tsv"
   USING DefaultTextOutputter();
```
 
2. Click **Save As**, name the file **test.script**, and save it in the root of your **CosmosSamples** folder. (Example: `C:\ScopeSDK\CosmosSamples`)



2. Open the **Command Prompt** and run the following script:

   ```
   C:\ScopeSDK\scope.exe run -i C:\ScopeSDK\CosmosSamples\test.script
   ```
   **Note:** `C:\SCOPESDK\scope.exe` is solely based on the location of your **SCOPESDK** root folder. If you receive the following error message, you may need to unblock the bits that you installed (see the [important note above](#download-the-SCOPE-SDK-and-CosmosSamples)): 
    
```
ScopeClient.CompilationErrorException: E_RUNTIME_USER_EXTERNALCSHARPCODEFAILEDTOCOMPILE: Could not load file or assembly 'Microsoft.CodeDom.Providers.DotNetCompilerPlatform, Version=2.0.1.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35' or one of its dependencies. The system cannot find the file specified.
Description:
A build error has occurred when C# compiler or linker tried to build the user's managed code.
```



3. When a script is run, the following output file will be created in this location: 

   `.../CosmosSamples/VCROOT/local/users/alias/output.tsv`


**Remarks**

- The `run` parameter means to compile and run a script.

- The `-i` parameter indicates the input script.

  **Note:** When a script is run, it will create a *LOT* of output on the console. At the very end, it will say **Done** for a successful result.

  ![image.png](/.attachments/image-abbd6d05-8f7a-44b8-9e55-134b82eed98b.png)

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Grouping and aggregation/DISTINCT with aggregates
# Overview

Every aggregate function can take a **DISTINCT** qualifier.

##Code sample

```scala
COUNT(DISTINCT x)
AVG(DISTINCT x)
```

**DISTINCT** also works for user-defined aggregates.

```scala
MyAggregator(DISTINCT x,y,z)
```
##Remarks
Runtime performance may be affected when **DISTINCT** is used or over-used. 

---

## Multiple distinct aggregates

SCOPE's existing multiple distinct aggregates execution strategy forks the input and computes each distinct aggregate on a fork, then joins them back together. A new rewrite has been implemented, which replicates the data in-place, instead of forking. Below is pseudo-SCOPE illustrating it. This rewrite is being used whenever it is legal to do so, as it performs better on average.

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span><br>
```scala
clicks = 
    SELECT * 
    FROM (VALUES
        ("2024-06-01", 1, 101),
        ("2024-06-01", 2, 102),
        ("2024-06-01", 1, 103),
        ("2024-06-02", 2, 101),
        ("2024-06-02", 3, 102),
        ("2024-06-02", 3, 103),
        ("2024-06-03", 1, 101),
        ("2024-06-03", 4, 104),
        ("2024-06-03", 4, 105)
    ) AS clicks(day, userId, machineId);

rs0 =
    SELECT day,
        COUNT(DISTINCT userId) AS cUID,
        COUNT(DISTINCT machineId) AS cMID
    FROM clicks
    GROUP BY day;


OUTPUT rs0
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span><br>
```scala
rs1 =
    SELECT *
    FROM clicks
         CROSS APPLY new List<int>{ 1, 2 } AS _selector;

rs2 =
    SELECT DISTINCT day,
                    _selector,
                    _selector == 1? userId : 0 AS userIdNew,
                    _selector == 2? machineId : 0 AS machineIdNew
    FROM rs1;

OUTPUT rs2
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>?</strong></span> Code Verified - June 2024</span></span><br>
```scala
rs3 = 
    SELECT day,
        COUNTIF(_selector == 1) AS cUID,
        COUNTIF(_selector == 2) AS cMID 
    FROM rs0;

OUTPUT rs3
    TO "/local/users/<your-alias>/output.txt"
    USING DefaultTextOutputter();
```

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Grouping and aggregation/Data types coming from aggregates

# Overview

Developers should be aware of how some aggregation operators deal with data types.

­­­­For example, the input data type is double:

- **SUM**(double) -> double
- **COUNT**(double) -> long(int64)

But if the input data type is numeric (long/int/short/byte, etc.):

- **SUM**(type) -> long(int64)
- **COUNT**(type) -> long(int64)

**Important:** Aggregates can ONLY appear in a [**SELECT**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3156/SELECT) clause.



Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Rowset manipulation
#Overview

A rowset is analogous to an in-memory table and stores tabular data, which is the basic unit of data storage between stages of a SCOPE job. Rowsets are generally manipulated by _column_ (selecting or transforming columns) and filtered by _row_ (using the **WHERE** or **HAVING** clauses). Rowsets can contain both primitive types and .NET types, which can be serialized between stages.

Rowsets are created when they are:
- Read from a structured or unstructured stream
- Derived from some other rowset 
- Created explicitly through use of the **VALUES** keyword 

The following code samples provide context for the above concepts:
- [**Code sample 1:** Creating a rowset with columns from an unstructured stream](#Code-sample-1%3A-Creating-a-rowset-with-columns-from-an-unstructured-stream)
- [**Code sample 2:** Creating a rowset and selecting columns from a previous rowset](#Code-sample-2%3A-Creating-a-rowset-and-selecting-columns-from-a-previous-rowset)
- [**Code sample 3:** Creating a named rowset with explicit values](#Code-sample-3%3A-Creating-a-named-rowset-with-explicit-values)
- [**Code sample 4:** Creating a rowset which includes rows with a matching rowset](#Code-sample-4%3A-Creating-a-rowset-which-includes-rows-with-a-matching-rowset)
- [**Code sample 5:** Filtering rowsets](#Code-sample-5%3A-Filtering-rowsets)
- [**Code sample 6:** Rowset overriding itself](#Code-sample-6%3A-Rowset-overriding-itself)
- [**Code sample 7:** Empty rowset with a desired schema can be constructed using VALUES](#Code-sample-7%3A-Empty-rowset-with-a-desired-schema-being-constructed-using-VALUES)

The following additonal topics are covered in this section:
- [Selecting and filtering rowsets](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Rowset-manipulation/Selection-and-filtering-rowsets)
- [Picking specific columns in rows](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Rowset-manipulation/Picking-specific-columns-in-rows)


##Syntax
```scala
rs1 =
 SELECT Start, Region, Duration
 FROM searchlog;

rs1 =
 SELECT *
 FROM rs1
 WHERE Start >= DateTime.Parse("2019/02/16") AND Start < DateTime.Parse("2019/02/17");

```

##Code sample 1: Creating a rowset with columns from an unstructured stream
```scala
searchlog = 
EXTRACT ImpressionId : int,
        Start : DateTime, 
        Region : string, 
        Query : string, 
        Duration : int, 
        Urls : string, 
        ClickedUrls : string
FROM “/local/Samples/SearchLog/SearchLog.tsv” 
USING DefaultTextExtractor(); 
```

The above sample creates the rowset named _searchlog_ with columns _ImpressionId_, _UserId_, _Start_, _Region_, _Query_, _Duration_, _Urls_, and _ClickedUrls_ from the tab separated, unstructured stream _SearchLog.tsv_ stored in Cosmos. 

The [**DefaultTextExtractor**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/DefaultTextExtractor) splits lines in the file on tabs by default, and _DateTimes_ are parsed automatically.

##Code sample 2: Creating a rowset and selecting columns from a previous rowset
```scala
rs1 =
SELECT Start, Region
FROM searchlog;
```
This sample creates the rowset named _rs1_ by selecting columns from the previously existing rowset _searchlog_.

##Code sample 3: Creating a named rowset with explicit values
```scala
regionsOfInterest = SELECT Region FROM (VALUES (“WA”), (“CA”)) AS Regions(Region:string);
```
This sample creates the rowset named _regionsOfInterest_ with explicitly provided values.

```scala
SELECT * FROM (VALUES(1, d2), (11, a22)) AS RowSet1(col1:int, col2:string)
```
This sample will generate a rowset RowSet1 with column col1 and col2 consisting of 2 rows. Col1 is of type int and Col2 is of type string. 

##Code sample 4: Creating a rowset which includes rows with a matching rowset
```scala
dataOfInterest = SELECT rs1.* FROM rs1 LEFT SEMIJOIN regionsOfInterest ON rs1.Region == regionsOfInterest.Region;
```
This sample creates the rowset _dataOfInterest_ derived from _rs1_, which includes only rows with a matching _Region_ from the _regionsOfInterest_ rowset.

##Code sample 5: Filtering rowsets
```scala
filteredData = SELECT * FROM dataOfInterest WHERE Start < DateTime.Parse(“2019-01-01”);
```

This sample creates the rowset _filteredData_ by filtering out any row that doesn’t have a start time prior to January 1, 2019.

##Code sample 6: Rowset overriding itself
```scala
rs1 = SELECT * FROM rs1 WHERE Start < DateTime.Parse(“2019-01-01”);
```
Statements later in the script will use the most recent rowset.

##Code sample 7: Empty rowset with a desired schema being constructed using VALUES
```scala
nullRowset = SELECT X, Y, Z FROM (VALUES (1,2,3)) AS Data(X:int,Y:int,Z:int) WHERE false;
```
**Note:** Empty rowsets are useful for handling inputs that may not exist.





Wiki Page: /SCOPE Language/SCOPE Tutorial/2: Parameters & the preprocessor
[[_TOC_]]


#Overview

Parameters are variables that are declared in the SCOPE script. They can also be passed to Views, Functions, and Procedures. These increase the dynamicity of the modular parts of the SCOPE Script. These also include the preprocessor variables whose values can be provided during the submission of the script to the cluster.

Like preprocessor parameters, when they are in the body of the View, Function, or Procedure, they will appear like this: **@foo**.

**Note:** **@** is used in front of C# string literals to specify that they are verbatim string literals.

---

## Two types of Parameters

1. [**Internal parameters**](/SCOPE-Language/SCOPE-Tutorial/2:-Parameters-&-the-preprocessor/Internal-parameters) ( _New-Style Parameters_ )
   -  The values for these parameters are declared _inside_ the script.
   - They are passed into views or created by the [**#DECLARE**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/569/DECLARE-and-SET-(Preprocessor)) preprocessor keyword. 
   - They are set with [**#SET**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/569/DECLARE-and-SET-(Preprocessor)).
   - When used in a script, a preprocessor parameter will look like this: **@foo**. A single **@** sign prefix identifies "foo" as a preprocessor parameter. 
   - They can be assigned expressions.
1. [**External parameters**](/SCOPE-Language/SCOPE-Tutorial/2:-Parameters-&-the-preprocessor/External-parameters) ( _Old-Style Parameters_ )
   - The values of these parameters are not in the SCOPE script -- instead, the values are provided by the user when the script is run.
   - These are passed into the main script from an API or the command line. 
   - When used in a script, a script submission parameter will look like this: **@@foo@@** - a pair of **@@** symbols surround "foo" and identify it as a _Script Parameter_. 
   - Their values are single tokens or comma-separated lists of single tokens.

---

##Preprocessor

The preprocessor is a special, limited language that is fully interpreted by SCOPE before the script is compiled. All statements starting with # are preprocessor statements.

Like preprocessors in other languages, the SCOPE preprocessor allows users to do several things:

- Define values that can be reused in the script -- these are the preprocessor parameters we mentioned earlier that are created via the [**#DECLARE**]https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/569/DECLARE-and-SET-(Preprocessor)) keyword.
- Set values using the [**#SET**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/569/DECLARE-and-SET-(Preprocessor)) keyword.
- Switch between alternating sections of code depending on some condition using the [**#IF**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/571/IF...ELSE-(Preprocessor)) and [**#ELSE**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/571/IF...ELSE-(Preprocessor)) keywords.

---

## See also
- [Preprocessors](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/302/Preprocessors)

---
# How to Engage, Contribute, and Provide Feedback
- Use [MS Stack Overflow](https://aka.ms/StackOverFlowSCOPE) for basic inquiries. Tag your questions with "**scope-parameters**", "**scope-preprocessor**" or "**preprocessor**" for questions regarding this topic.
- For general Cosmos email discussion and community support, join [Cosmos Discussion](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join [Cosmos Announcements](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Details here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

Wiki Page: /SCOPE Language/SCOPE Tutorial/3: Combining rowsets with set operations
# Overview

SCOPE can combine multiple rowsets to form a new rowset in three different ways:
1. Using the rowset [**JOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs) operations
1. [**Set Operations**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/Set-operations) like UNION and INTERSECT.
1. [**Combiner UDOs**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/Custom-JOINs-via-Combiners) 

---

## Scenario
Given two rowsets A and B as shown below:

| A      |       |   | B      |       |
|--------|-------|---|--------|-------|
| id:int | Name  |   | id:int | Name  |
| 1      | Smith |   | 1      | Smith |
| 1      | Smith |   | 1      | Smith |
| 2      | Brown |   | 1      | Smith |
| 3      | Case  |   | 2      | Brown |
|        |       |   | 4      | Dey   |
|        |       |   | 4      | Dey   |

Load these datasets from the samples:
 
```scala
a = EXTRACT 
        Id:int, 
        Name:string
    FROM @"/local/Samples/SampleData/SetOps/A.txt"
    USING DefaultTextExtractor()
    ;

b = EXTRACT 
        Id:int, 
         Name:string
    FROM @"/local/users/<your alias>/SampleData/SetOps/B.txt"
    USING DefaultTextExtractor()
    ;
```
Or Create a rowset using VALUES():
```scala
a = SELECT * 
    FROM (VALUES
        (1, "Smith"),
        (1, "Smith"),
        (2, "Brown"),
        (3, "Case")
    ) AS ord(id,name)
    ;

b = SELECT * 
    FROM (VALUES
        (1, "Smith"),
        (1, "Smith"),
        (1, "Smith"),
        (2, "Brown"),
        (4, "Dey"),
        (4, "Dey")
    ) AS ord(id,name)
    ;
```
---

##See also
- [EXTRACT](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT)
- [FROM](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT/FROM)
- [USING](/SCOPE-Language/SCOPE-Language-Reference/User-defined-operators-\(UDOs\)/Clauses-and-Functions/USING)
- [DefaultTextExtractor](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/DefaultTextExtractor)



Wiki Page: /SCOPE Language/SCOPE Tutorial/3: Combining rowsets with set operations/Merging rows with UNION
#Overview
Combining two rowsets is done with the [**UNION**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/542/UNION) operator.
**UNION ALL** will preserve any duplicates while **UNION** will remove them.

---

##Code sample
```scala
rs0 =    
    SELECT * FROM a
  UNION DISTINCT
    SELECT * FROM b;  

rs1 =         
    SELECT * FROM a
  UNION ALL
    SELECT * FROM b;  

OUTPUT rs0 TO @"/local/users/<your alias>/Outputs/union_distinct.txt";
OUTPUT rs1 TO @"/local/users/<your alias>/Outputs/union_all.txt";
```

##Results
[ **rs0** ] -  _UNION DISTINCT_    

|  id:int | Name  |
|---|---|
| 1  |Smith   |
| 2  |Brown   |
| 3  | Case  |
| 4  | Dey  |

[ **rs1** ] -  _UNION ALL_

|id:int| Name |
|--|--|
| 1 | Smith |
| 1 | Smith |
|2  | Brown |
| 3 | Case |
| 1 | Smith |
| 1 | Smith |
| 1 | Smith |
| 2 |Brown  |
|4  | Dey |
| 4 | Dey |

---

##See also
- [Set operations](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3158/Set-operations)
- [UNION](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/542/UNION)

Wiki Page: /SCOPE Language/SCOPE Tutorial/3: Combining rowsets with set operations/Finding common rows with INTERSECT
#Overview
Sometimes, users only care about the rows both rowsets have in common. The **INTERSECT** operator can be used to accomplish this. **INTERSECT ALL** preserves duplicates while **INTERSECT** removes 
duplicates.

---

##Code sample

Using the data in [Combining rowsets with set operations](/SCOPE-Language/SCOPE-Tutorial/3:-Combining-rowsets-with-set-operations), the following script will display the listed results.

```scala
rs1 =  
    SELECT * FROM a 
  INTERSECT DISTINCT
    SELECT * FROM b;

rs2 =  
    SELECT * FROM a 
  INTERSECT ALL
    SELECT * FROM b;

OUTPUT rs1 TO @"/local/users/<your alias>/Outputs/intersect.txt";
OUTPUT rs2 TO @"/local/users/<your alias>/Outputs/intersect-all.txt";
```
## Results

[ **rs1** ] - _INTERSECT DISTINCT_

|id:int| name |
|--|--|
|1  | Smith |
| 2 | Brown |

[ **rs2** ] - _INTERSECT ALL_

|id:int| name |
|--|--|
|  1| Smith |
| 1 |Smith  |
| 2| Brown|

---

## See also
- [Merging rows with UNION](/SCOPE-Language/SCOPE-Tutorial/3:-Combining-rowsets-with-set-operations/Merging-rows-with-UNION)

Wiki Page: /SCOPE Language/SCOPE Tutorial/3: Combining rowsets with set operations/Finding rows that are NOT in the other rowset with EXCEPT
#Overview
The **EXCEPT** operator returns all the rows in the left rowset that are not in the right rowset.

---

##Code samples

Using the data in [Combining rowsets with set operations](/SCOPE-Language/SCOPE-Tutorial/3:-Combining-rowsets-with-set-operations), the following script will display the listed results.

```scala
rs0 = 
    SELECT * FROM a 
  EXCEPT DISTINCT
    SELECT * FROM b;

rs1 = 
    SELECT * FROM a 
  EXCEPT ALL
    SELECT * FROM b;

rs2 = 
    SELECT * FROM b 
  EXCEPT DISTINCT
    SELECT * FROM a;

rs3 = 
    SELECT * FROM b 
  EXCEPT ALL
    SELECT * FROM a;

OUTPUT rs0 TO @"/local/users/<your alias>/Outputs/except_distinct_a_b.txt";
OUTPUT rs1 TO @"/local/users/<your alias>/Outputs/except-all_a_b.txt";
OUTPUT rs2 TO @"/local/users/<your alias>/Outputs/except_distinct_b_a.txt";
OUTPUT rs3 TO @"/local/users/<your alias>/Outputs/except-all_b_a.txt";
```

## Results

[ **rs0** ] - _EXCEPT DISTINCT (A,B)_

|id:int| name |
|--|--|
| 3 | Case |

[ **rs1** ] - _EXCEPT ALL (A,B)_

|id:int| name |
|--|--|
|3  |  Case|

[ **rs2** ] - _EXCEPT DISTINCT (B,A)_

|id:int| name |
|--|--|
|4  | Dey |

[ **rs3** ] - _EXCEPT ALL (B,A)_

|id:int| name |
|--|--|
|  1|Smith  |
|  4| Dey |
| 4 | Dey |


---

## See also

- [3: Combining rowsets with set operations](/SCOPE-Language/SCOPE-Tutorial/3:-Combining-rowsets-with-set-operations)
- [Finding common rows with INTERSECT](/SCOPE-Language/SCOPE-Tutorial/3:-Combining-rowsets-with-set-operations/Finding-common-rows-with-INTERSECT)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs
# Overview
**JOIN** operators combine rowsets into a new rowset based on matching a field in one rowset to a field in another rowset. 

The following topics are covered in this section:
- [JOIN best practices](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-best-practices)
- [CROSS JOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/CROSS-JOIN)
- [INNER JOIN and OUTER JOIN datasets](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/INNER-JOIN-and-OUTER-JOIN-datasets)
- [JOIN code samples](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples)
- [Custom JOINS via Combiners](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/Custom-JOINs-via-Combiners)


---
# How to Engage, Contribute, and Provide Feedback
- Use [MS Stack Overflow](https://aka.ms/StackOverFlowSCOPE) for basic inquiries. Tag your questions with "**scope-join**" for questions regarding this topic.
- For general Cosmos email discussion and community support, join [Cosmos Discussion](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join [Cosmos Announcements](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Details here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/INNER JOIN and OUTER JOIN datasets/Example dataset 1
# Overview
Consider the following rowsets:

![image.png](/.attachments/image-6717d20c-b42d-4b7c-ad93-3c33e8b676c0.png)

- An **INNER JOIN** of these two rowsets will return the combined rows where the **DepID** field matches.
- A **LEFT OUTER JOIN** is a superset of the **INNER JOIN** that includes ALL the rows from the left rowset. Because D3 is not present in the right rowset, NULL values are used for that output row.
- A **RIGHT OUTER JOIN** is a superset of the **INNER JOIN** that includes ALL the rows from the right rowset. Because D2 is not present in the right rowset, NULL values are used for that output row.
- A **FULL OUTER JOIN** is a combination of the **LEFT OUTER** and **RIGHT OUTER JOIN**
- Using **OUTER JOIN** without specifying **LEFT**, **RIGHT**, or **FULL** indicates a **LEFT OUTER JOIN**.

![image.png](/.attachments/image-3b636b73-0f28-431a-84f5-f8965fbff7a3.png)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/INNER JOIN and OUTER JOIN datasets/Example dataset 2
# Overview
Let's add an extra employee to the original data. In this case _Smith_ is also assigned to _D1_. See how this changed the results:

![image.png](/.attachments/image-ccd6c110-0929-48cb-a7d9-6fc09f5cd4e4.png)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/INNER JOIN and OUTER JOIN datasets/Example dataset 3
# Overview
Now let's add another department – but notice that this department is also assigned to D1. \
![image.png](/.attachments/image-6da8d3ba-12f8-4de5-b594-106ea23787ed.png)



Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/INNER JOIN and OUTER JOIN datasets
#Overview
The following datasets and code sample are provided to describe **INNER JOIN** and **OUTER JOIN**:
- [Example dataset 1](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/INNER-JOIN-and-OUTER-JOIN-datasets/Example-dataset-1)
- [Example dataset 2](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/INNER-JOIN-and-OUTER-JOIN-datasets/Example-dataset-2)
- [Example dataset 3](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/INNER-JOIN-and-OUTER-JOIN-datasets/Example-dataset-3)
- [Code sample](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/INNER-JOIN-and-OUTER-JOIN-datasets/Code-sample)


Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/CROSS JOIN
#Overview
**CROSS JOIN** is basically an **INNER JOIN** without a join condition – it returns all the possible combinations of records. This is the Cartesian product of the records in both rowsets.

![image.png](/.attachments/image-ca9bf6b3-63f2-4372-995a-db44165d4c94.png)




Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/CROSS JOIN/SEMIJOIN
#Overview

It is easiest to think of **SEMIJOIN** as a filter for a rowset. There are two variants:

1. **LEFT SEMIJOIN** - gives only those rows in the **left rowset** that have a matching row in the **right rowset**.
1. **RIGHT SEMIJOIN** - gives only those rows in the **right rowset** that have a matching row in the **left rowset**.

When using **SEMIJOIN**, always specify if you're using a `RIGHT` or `LEFT` semijoin. Without the direction qualifier, it will default to **LEFT SEMIJOIN**.

---

Let's consider the following examples,
<br/>
**Department.tsv**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|
|600|IT|


**Employee.tsv**
|EmpNo|EmpName|DepID|Salary|
|--|--|--|--|
|1|Noah|100|10000|
|2|Sophia|100|20000|
|3|Liam|100|30000|
|4|Emma|200|10000|
|5|Jacob|200|10000|
|6|Olivia|200|10000|
|7|Mason|300|50000|
|8|Ava|400|15000|
|9|Ethan|400|10000|
|10|Kirsten|500|15000|
|11|Celestine|500|10000|

---

##Code sample 1
Find all employees that have valid departments (find all the employees in the left rowset that have a departmentid that is listed in the right rowset):

```scala
EmployeewithValidDept =
    SELECT employees.EmpName,
           employees.DepID
    FROM employees
         LEFT SEMIJOIN
             departments
         ON employees.DepID == departments.DepID;

OUTPUT EmployeewithValidDept
TO SSTREAM @"/Output/EmployeewithValidDept.ss";
```

**Output:**
|EmpNo|EmpName|
|--|--|
|Noah|100|
|Sophia|100|
|Liam|100|
|Emma|200|
|Jacob|200|
|Olivia|200|
|Mason|300|
|Ava|400|
|Ethan|400|


##Code sample 2
Find all departments with at least one employee:
```scala
DeptwithEmployees =
    SELECT departments.DepID,
           departments.DepName
    FROM employees 
    RIGHT SEMIJOIN departments 
        ON employees.DepID == departments.DepID;

OUTPUT DeptwithEmployees
TO SSTREAM @"/Output/DeptwithEmployees.ss";
```

**Output:**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|


**NOTE:** You can only query from the main rowset specified on your query, the joining rowset cannot be queried when using **SEMI JOIN** and will return an error. In sample 1 you cannot specify `departments.DepID` or `departments.DepName` since you can only query from the **left rowset** which is the `employees` rowset. While in sample 2, you cannot query fields from `employees` rowset.

<hr>


## See also
- [INNER JOIN and OUTER JOIN datasets](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/INNER-JOIN-and-OUTER-JOIN-datasets)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples/ANTISEMIJOIN
# Overview

Anti-Semijoins are SCOPE’s way to filter a rowset based on the absence of its rows in another rowset. There are two variants: **LEFT ANTISEMIJOIN** and **RIGHT ANTISEMIJOIN**.

A **LEFT ANTISEMIJOIN** (or just **ANTISEMIJOIN**) gives only those rows in the left rowset that have no matching row in the right rowset.

The **RIGHT ANTISEMIJOIN** gives only those rows in the right rowset that have no matching row in the left rowset.

The join expression in the **ON** clause specifies how to determine the match.

---

## Dataset
Given the following rowsets:

|EmpName  | DepID |
|--|--|
| Rafferty | 31 |
| Jones | 33 |
|Steinberg  |  33|
|  Robinson| 34|
|  Smith|34  |
| John |  NULL|

|  DepID|  DepName|
|--|--|
| 31 | Sales |
| 33 | Engineering|
| 34 |  Clerical|
|35  | Marketing |

---

## Code samples
The following query finds all employees that are not in a valid department by finding all the employees in the left employees rowset that do not have a `depID` that is listed in the right department's rowset:

``` scala
employees = 
    SELECT *  
    FROM (VALUES   
            ("Rafferty", (int?) 31),
            ("Jones", (int?) 33),
            ("Steinberg", (int?) 33),
            ("Robinson", (int?) 34),
            ("Smith", (int?) 34),
            ("Williams", (int?) null)
    ) AS employees (EmpName, DepID);  
                      
departments = 
    SELECT *  
    FROM (VALUES  
        ((int) 31, "Sales"),
        ((int) 33, "Engineering"),
        ((int) 34, "Clerical"),
        ((int) 35, "Marketing")
    ) AS departments (DepID, DepName);  

emps_notin_valid_dept = 
    SELECT EmpName, DepID
    FROM employees 
    LEFT ANTISEMIJOIN (SELECT (int?) DepID AS DepID, DepName FROM departments) AS departments
        ON employees.DepID == departments.DepID;  
  
  
OUTPUT emps_notin_valid_dept   
    TO "/output/rsLeftAntiSemiJoinEmployeesNotInValidDept.csv"  
    USING Outputters.Csv();
```

The resulting rowset looks like this:

|EmpName  | DepID |
|--|--|
| Williams | null |

The following query finds all departments without an employee:

```scala
employees = 
    SELECT *  
    FROM (VALUES   
        ("Rafferty", (int?) 31),
        ("Jones", (int?) 33),
        ("Steinberg", (int?) 33),
        ("Robinson", (int?) 34),
        ("Smith", (int?) 34),
        ("Williams", (int?) null)
    ) AS employees (EmpName, DepID);  
                      
departments = 
    SELECT *  
    FROM (VALUES  
            ((int) 31, "Sales"),
            ((int) 33, "Engineering"),
            ((int) 34, "Clerical"),
            ((int) 35, "Marketing")
    ) AS departments (DepID, DepName);  
                       
depts_without_emps =  
    SELECT DepName, DepID  
    FROM employees
    RIGHT ANTISEMIJOIN (SELECT (int?) DepID AS DepID, DepName FROM departments) AS departments   
        ON employees.DepID == departments.DepID;  

OUTPUT depts_without_emps
    TO "/output/rsRightAntiSemiJoinDeptsWithoutEmployees.csv"  
    USING Outputters.Csv();
```

Both queries return the same rowset:

|  DepName| DepID |
|--|--|
|Marketing  | 35 |


---

## See also
- [Custom JOINs via Combiners](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/Custom-JOINs-via-Combiners)
- [JOIN code samples](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/CROSS JOIN/Don’t use implicit JOINs
# Overview
At some point, users may come across a **JOIN** that looks like this:

```scala
employeeDept = 
    SELECT 
        employees.DepartmentID AS EmpDepartmentId, 
        departments.DepartmentID AS DepDepartmentID, 
        employees.LastName, 
        departments.DepartmentName
    FROM employees, departments
    WHERE employees.DepartmentID == departments.DepartmentID;
```

##Remarks
- There’s a **JOIN** operation specified.
- The **FROM** clause contains a comma-separated list of rowsets.
- There’s a **WHERE** clause instead of an **ON** clause.
- This example uses an <mark>**Implicit INNER JOIN**</mark>.  Users must **always be explicit** about their joins. **Don’t use Implicit INNER JOIN, instead make it explicit.**

**ProTip:** in some SQL variants – but not SCOPE - the **WHERE** condition is optional. When it doesn’t appear, this implicit join behaves as a **CROSS JOIN**. It’s easy to accidentally do an (expensive) **CROSS JOIN** when using such a syntax. For this reason, **Implicit Join** should be avoided even in languages that support it.
 

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples
#Overview
The following **JOIN** code samples are provided in this section:
- [**INNER JOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/INNER-JOIN)
- [**LEFT OUTER JOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/LEFT-OUTER-JOIN)
- [**RIGHT OUTER JOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/RIGHT-OUTER-JOIN)
- [**CROSS JOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/CROSS-JOIN)
- [**LEFT SEMIJOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/LEFT-SEMIJOIN)
- [**RIGHT SEMIJOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/RIGHT-SEMIJOIN)
- [**FULL OUTER JOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/FULL-OUTER-JOIN)
- [**ANTISEMIJOIN**](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/ANTISEMIJOIN)






Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples/INNER JOIN
#Overview

an **INNER JOIN** returns a rowset that satisfies the condition specified on the join comparison predicate.

<hr>

##Dataset
Given the following input rowsets:
<br/>

**Employee.tsv**
|EmpNo|EmpName|DepID|Salary|
|--|--|--|--|
|1|Noah|100|10000|
|2|Sophia|100|20000|
|3|Liam|100|30000|
|4|Emma|200|10000|
|5|Jacob|200|10000|
|6|Olivia|200|10000|
|7|Mason|300|50000|
|8|Ava|400|15000|
|9|Ethan|400|10000|
|10|Kirsten|500|15000|
|11|Celestine|500|10000|

**Department.tsv**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|
|600|IT|

<hr>

## Code Sample: INNER JOIN
If we execute the following script, using DepID from employees and DepId from departments as comparison predicate.

```scala
innerJoinEmpDept = 
    SELECT 
        employees.DepID AS EmpDepId, 
        departments.DepID , 
        employees.EmpName, 
        departments.DepName
    FROM employees 
    INNER JOIN departments 
        ON employees.DepID == departments.DepID;

OUTPUT innerJoinEmpDept TO @"Output.txt";
```
**Output:** \
It will return all the `employees` that have a match on the `departments` rowset.

| EmpDepId|DepID|EmpName|DepName|
|--|--|--|--|
|100|100|Noah|Engineering|
|100|100|Sophia|Engineering|
|100|100|Liam|Engineering|
|200|200|Emma|HR|
|200|200|Jacob|HR|
|200|200|Olivia|HR|
|300|300|Mason|Executive|
|400|400|Ava|Marketing|
|400|400|Ethan|Marketing|


**Note:** If a user leaves out **INNER** or **OUTER** and instead simply writes **JOIN**, then they will automatically get an **INNER JOIN**. Do not leave out **INNER** or **OUTER** when writing code. Always explicitly use it.

--- 
##See also
- [LEFT OUTER JOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/LEFT-OUTER-JOIN)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples/LEFT OUTER JOIN
## Code Sample: LEFT OUTER JOIN

The **LEFT OUTER JOIN** clause returns a result set that has a match on the left and right table. It returns `NULL` on the right side if there is no match.

<hr>

## Dataset

Given the following input rowsets:

**Employee.tsv**
|EmpNo|EmpName|DepID|Salary|
|--|--|--|--|
|1|Noah|100|10000|
|2|Sophia|100|20000|
|3|Liam|100|30000|
|4|Emma|200|10000|
|5|Jacob|200|10000|
|6|Olivia|200|10000|
|7|Mason|300|50000|
|8|Ava|400|15000|
|9|Ethan|400|10000|
|10|Kirsten|500|15000|
|11|Celestine|500|10000|

**Department.tsv**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|
|600|IT|

<hr>

## Code Sample: LEFT OUTER JOIN
```scala
AllEmployees = 
    SELECT 
        employees.DepID AS EmpDepId, 
        departments.DepID, 
        employees.EmpName, 
        departments.DepName
    FROM employees 
    LEFT OUTER JOIN departments 
        ON employees.DepID == departments.DepID;
```

**Output:**
|EmpDepId|DepID|EmpName|DepName|
|--|--|--|--|
|100|100|Noah|Engineering|
|100|100|Sophia|Engineering|
|100|100|Liam|Engineering|
|200|200|Emma|HR|
|200|200|Jacob|HR|
|200|200|Olivia|HR|
|300|300|Mason|Executive|
|400|400|Ava|Marketing|
|400|400|Ethan|Marketing|
|500||Kirsten||
|500||Celestine||

---
## See also
- [RIGHT OUTER JOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/RIGHT-OUTER-JOIN)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples/RIGHT OUTER JOIN
#Overview
The **RIGHT OUTER JOIN** clause returns a result set that has a match on the left and right table. It returns `NULL` on the left side if there is no match.

**Note:** If a user leaves out **LEFT** or **RIGHT** and instead simply writes **OUTER JOIN**, they will end up with **LEFT OUTER JOIN**. Do not leave out **LEFT** or **RIGHT** when writing code. Always explicitly write it out.

<hr>

## Dataset

Given the following input rowsets:
<br/>

**Employee.tsv**
|EmpNo|EmpName|DepID|Salary|
|--|--|--|--|
|1|Noah|100|10000|
|2|Sophia|100|20000|
|3|Liam|100|30000|
|4|Emma|200|10000|
|5|Jacob|200|10000|
|6|Olivia|200|10000|
|7|Mason|300|50000|
|8|Ava|400|15000|
|9|Ethan|400|10000|
|10|Kirsten|500|15000|
|11|Celestine|500|10000|

**Department.tsv**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|
|600|IT|

<hr>

## Code sample: RIGHT OUTER JOIN
```scala
AllDept = 
    SELECT 
        employees.DepID AS EmpDepId, 
        departments.DepID, 
        employees.EmpName, 
        departments.DepName
    FROM employees 
    RIGHT OUTER JOIN departments 
        ON employees.DepID == departments.DepID;
```
**Output:**
|EmpDepId|DepID|EmpName|DepName|
|--|--|--|--|
|100|100|Liam|Engineering|
|100|100|Sophia|Engineering|
|100|100|Noah|Engineering|
|200|200|Olivia|HR|
|200|200|Jacob|HR|
|200|200|Emma|HR|
|300|300|Mason|Executive|
|400|400|Ethan|Marketing|
|400|400|Ava|Marketing|
||600||IT|

---


## See also
- [CROSS JOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/CROSS-JOIN)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples/FULL OUTER JOIN
# Overview
The **FULL OUTER JOIN** clause returns a result set that is a combination of **LEFT OUTER JOIN** and **RIGHT OUTER JOIN**. The right table will return `NULL` if the left table has no matching records and vice versa.
<hr>

## Dataset

Given the following input rowsets:
<br/>

**Employee.tsv**
|EmpNo|EmpName|DepID|Salary|
|--|--|--|--|
|1|Noah|100|10000|
|2|Sophia|100|20000|
|3|Liam|100|30000|
|4|Emma|200|10000|
|5|Jacob|200|10000|
|6|Olivia|200|10000|
|7|Mason|300|50000|
|8|Ava|400|15000|
|9|Ethan|400|10000|
|10|Kirsten|500|15000|
|11|Celestine|500|10000|

**Department.tsv**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|
|600|IT|

<hr>

## Code sample: FULL OUTER JOIN
```scala
fullJoinEmpDept = 
    SELECT 
        employees.DepID AS EmpDepId, 
        departments.DepID , 
        employees.EmpName, 
        departments.DepName
    FROM employees 
    FULL OUTER JOIN departments 
        ON employees.DepID == departments.DepID;
```
**Output:**
The employee with has a

|EmpDepId|DepID|EmpName|DepName|
|--|--|--|--|
|100|100|Sophia|Engineering|
|100|100|Liam|Engineering|
|100|100|Noah|Engineering|
|200|200|Olivia|HR|
|200|200|Emma|HR|
|200|200|Jacob|HR|
|300|300|Mason|Executive|
|400|400|Ava|Marketing|
|400|400|Ethan|Marketing|
|500||Kirsten||
|500||Celestine||
||600||IT|


---

## See also

- [ANTISEMIJOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/ANTISEMIJOIN)
- [JOIN](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/SELECT/JOIN)
- [JOIN best practices](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-best-practices)


Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples/LEFT SEMIJOIN
#Overview

**LEFT SEMIJOIN** - gives only those rows in the **left rowset** that have a matching row in the right rowset.

<hr>

## Dataset

Given the following input rowsets:
<br/>

**Employee.tsv**
|EmpNo|EmpName|DepID|Salary|
|--|--|--|--|
|1|Noah|100|10000|
|2|Sophia|100|20000|
|3|Liam|100|30000|
|4|Emma|200|10000|
|5|Jacob|200|10000|
|6|Olivia|200|10000|
|7|Mason|300|50000|
|8|Ava|400|15000|
|9|Ethan|400|10000|
|10|Kirsten|500|15000|
|11|Celestine|500|10000|

**Department.tsv**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|
|600|IT|

<hr>

## Code sample: LEFT SEMIJOIN
```scala
employees = 
        EXTRACT 
            EmpID:string, 
            EmpName:string,  
            DepID:string, 
            Salary:double
        FROM @"/Input/Employee.tsv"
        USING DefaultTextExtractor();

departments = 
        EXTRACT 
            DepID:string, 
            DepName:string
        FROM @"/Input/Department.tsv"
        USING DefaultTextExtractor();


EmployeewithValidDept =
    SELECT employees.EmpName,
           employees.DepID
    FROM employees
         LEFT SEMIJOIN
             departments
         ON employees.DepID == departments.DepID;


OUTPUT EmployeewithValidDept
TO SSTREAM @"/Output/EmployeewithValidDept.ss";
```
---

## See also

**Output:**
It will return the records from the `employees` rowset.

|EmpName|DepID|
|--|--|
|Noah|100|
|Sophia|100|
|Liam|100|
|Emma|200|
|Jacob|200|
|Olivia|200|
|Mason|300|
|Ava|400|
|Ethan|400|

---
## See also

- [RIGHT SEMIJOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/RIGHT-SEMIJOIN)
- [SEMIJOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/CROSS-JOIN/SEMIJOIN)


Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples/RIGHT SEMIJOIN
#Overview

**RIGHT SEMIJOIN** - gives only those rows in the **right rowset** that have a matching row in the left rowset.

<hr>

Given the following rowsets: \
**Department.tsv**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|
|600|IT|


**Employee.tsv**
|EmpNo|EmpName|DepID|Salary|
|--|--|--|--|
|1|Noah|100|10000|
|2|Sophia|100|20000|
|3|Liam|100|30000|
|4|Emma|200|10000|
|5|Jacob|200|10000|
|6|Olivia|200|10000|
|7|Mason|300|50000|
|8|Ava|400|15000|
|9|Ethan|400|10000|
|10|Kirsten|500|15000|
|11|Celestine|500|10000|

<hr>

## Code sample: RIGHT SEMIJOIN
```scala
employees = 
        EXTRACT 
            EmpID:string, 
            EmpName:string,  
            DepID:string, 
            Salary:double
        FROM @"/Input/Employee.tsv"
        USING DefaultTextExtractor();

departments = 
        EXTRACT 
            DepID:string, 
            DepName:string
        FROM @"/Input/Department.tsv"
        USING DefaultTextExtractor();

DeptwithEmployees =
    SELECT departments.DepID,
           departments.DepName
    FROM employees 
    RIGHT SEMIJOIN departments 
        ON employees.DepID == departments.DepID;

OUTPUT DeptwithEmployees
TO SSTREAM @"/Output/DeptwithEmployees.ss";
```

**Output:**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|

---
## See also
- [SEMIJOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/CROSS-JOIN/SEMIJOIN)
- [LEFT SEMIJOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/LEFT-SEMIJOIN)
- [FULL OUTER JOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/FULL-OUTER-JOIN)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/JOIN code samples/CROSS JOIN
#Overview

A **CROSS JOIN** returns the Cartesian product of rows from the rowsets in the join. In other words, it will combine each row from the first rowset with each row from the second rowset.

**Protip:** Using **RIGHT OUTER JOIN**, **RIGHT SEMIJOIN** and **FULL OUTER JOIN** is quite rare.  **INNER JOIN**, **LEFT OUTER JOIN**, and **LEFT SEMIJOIN** are fairly common.  Aside from certain useful scenarios, **CROSS JOIN** should be avoided since it typically causes large data explosion.
<hr> 

## Dataset
Given the following input rowsets:
<br/>

**Employee.tsv**
|EmpNo|EmpName|DepID|Salary|
|--|--|--|--|
|1|Noah|100|10000|
|2|Sophia|100|20000|
|3|Liam|100|30000|
|4|Emma|200|10000|
|5|Jacob|200|10000|
|6|Olivia|200|10000|
|7|Mason|300|50000|
|8|Ava|400|15000|
|9|Ethan|400|10000|
|10|Kirsten|500|15000|
|11|Celestine|500|10000|

**Department.tsv**
|DepID|DepName|
|--|--|
|100|Engineering|
|200|HR|
|300|Executive|
|400|Marketing|
|600|IT|

<hr> 

## Code sample: CROSS JOIN

```scala
crossJoinEmpDept = 
    SELECT 
        employees.DepID AS EmpDepId, 
        departments.DepID, 
        employees.EmpName, 
        departments.DepName
    FROM employees 
    CROSS JOIN departments;
```
**Output:** \
It will combine each row from `employee` rowset with each row of the `department` rowset. 

|EmpDepId|DepID|EmpName|DepName|
|--|--|--|--|
|100|100|Noah|Engineering|
|100|200|Noah|HR|
|100|300|Noah|Executive|
|100|400|Noah|Marketing|
|100|600|Noah|IT|
|100|100|Sophia|Engineering|
|100|200|Sophia|HR|
|100|300|Sophia|Executive|
|100|400|Sophia|Marketing|
|100|600|Sophia|IT|
|100|100|Liam|Engineering|
|100|200|Liam|HR|
|100|300|Liam|Executive|
|100|400|Liam|Marketing|
|100|600|Liam|IT|
|200|100|Emma|Engineering|
|200|200|Emma|HR|
|200|300|Emma|Executive|
|200|400|Emma|Marketing|
|200|600|Emma|IT|
|200|100|Jacob|Engineering|
|200|200|Jacob|HR|
|200|300|Jacob|Executive|
|200|400|Jacob|Marketing|
|200|600|Jacob|IT|
|200|100|Olivia|Engineering|
|200|200|Olivia|HR|
|200|300|Olivia|Executive|
|200|400|Olivia|Marketing|
|200|600|Olivia|IT|
|300|100|Mason|Engineering|
|300|200|Mason|HR|
|300|300|Mason|Executive|
|300|400|Mason|Marketing|
|300|600|Mason|IT|
|400|100|Ava|Engineering|
|400|200|Ava|HR|
|400|300|Ava|Executive|
|400|400|Ava|Marketing|
|400|600|Ava|IT|
|400|100|Ethan|Engineering|
|400|200|Ethan|HR|
|400|300|Ethan|Executive|
|400|400|Ethan|Marketing|
|400|600|Ethan|IT|
|500|100|Kirsten|Engineering|
|500|200|Kirsten|HR|
|500|300|Kirsten|Executive|
|500|400|Kirsten|Marketing|
|500|600|Kirsten|IT|
|500|100|Celestine|Engineering|
|500|200|Celestine|HR|
|500|300|Celestine|Executive|
|500|400|Celestine|Marketing|
|500|600|Celestine|IT|

---

## See also
- [LEFT SEMIJOIN](/SCOPE-Language/SCOPE-Tutorial/4:-Combining-rowsets-with-JOINs/JOIN-code-samples/LEFT-SEMIJOIN)

Wiki Page: /SCOPE Language/SCOPE Tutorial/4: Combining rowsets with JOINs/Custom JOINs via Combiners
# Overview

Users can implement their own **JOINs** using [Combiner UDOs](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/432/Combiner-(CSharp-UDO)).
This section will illustrate the usage in a SCOPE script, but will not go into how to create one.

##Syntax

```xml
rs2 = COMBINE <left> WITH <right>
      ON left.X == right.X
      USING <MyCombiner()>
      PRODUCE A,B,C,D;
```
**_<left>_** left schema to be combined

**_<right>_** right schema to be combined

**_<MyCombiner()>_** user-created combiner implementing Combiner. 

##Code Sample

```scala
rs2 = 
    COMBINE left WITH right
    ON left.X == right.X
    USING MyCombiner()
    PRODUCE A,B,C,D;
```
##Remarks
- Multiple rowset inputs are identified. 
- Rows are combined **ON** a specific column from each rowset.
- The **USING** clause specifies the Combiner.
- The **PRODUCE** clause identifies the schema that is returned from the operation. 

---

## See also
- [Combiner](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/432/Combiner-(CSharp-UDO))

Wiki Page: /SCOPE Language/SCOPE Tutorial/5: Reading and writing files
<font color="red"><big>**Important:**</big></font>  
If having trouble connecting or submitting jobs to Cosmos/ADLS accounts, make sure to access them within **corpnet**.  
See [Corpnet Requirement](/Accessing-Cosmos-Network/Corpnet-Requirement-when-Accessing-Cosmos) for more information.

# Overview
A file (aka _streamset_) can refer to either: 
- A pattern string used to identify files
- The files that match that specific pattern 

The [**OUTPUT**](/SCOPE-Language/SCOPE-Language-Reference/OUTPUT-statement) command lets users persist a rowset into a Cosmos file. Unless otherwise specified, SCOPE will use the [**DefaultTextOutputter**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/DefaultTextOutputter) to output a file. 

**Note:** Streamsets represent a shared convention between Cosmos and its users; however, streamsets are not “objects" in the Cosmos system.  

The following topics are covered in this section:
- [Streamsets](/SCOPE-Language/SCOPE-Tutorial/5:-Reading-and-writing-files/Streamsets)
- [Extracting and Extractors](/SCOPE-Language/SCOPE-Tutorial/5:-Reading-and-writing-files/Extracting-and-extractors)
- [Outputting and Outputters](/SCOPE-Language/SCOPE-Tutorial/5:-Reading-and-writing-files/Outputting-and-outputters)

##Streamsets are not regular expressions 
Streamsets ultimately define a simple pattern language for stream names. However, the patterns are defined by the SCOPE language. Streamset matching is much less powerful than regular expression matching. 

Most of the examples have focused on unstructured streams. Structured streams have additional metadata and indexing in them. 
## Creating a structured stream
Let's take the searchlog unstructured stream and save it as a structured stream.
```scala
searchlog = VIEW @"/local/Samples/Views/SearchLog.view";

OUTPUT searchlog TO SSTREAM "searchlog.ss"
    CLUSTERED BY Region 
    SORTED BY Region;
```

**Protip:** The [**CLUSTERED BY**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/Sorting-and-partitioning-data/CLUSTERED-BY) and [**SORTED BY**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/Sorting-and-partitioning-data/SORTED-BY) clauses are optional but it is **HIGHLY RECOMMEND** that developers **ALWAYS** use them when creating a structured stream. For more information, see the [Performance](/Performance) section of the wiki.
## Reading from a structured stream
Now that we have a structured stream to use, let's read from it:
```scala
searchlog_ss = SSTREAM "searchlog.ss";

searchlog = 
    SELECT * 
    FROM searchlog_ss
    WHERE Region == "en-us";

OUTPUT searchlog TO "/local/users/<your alias>/Outputs/output.txt"; 
```

## SSv5 reads on ADLS Gen 1
Reading SSv5 streams is only supported in ADLS Gen2. As of March 2022, SCOPE will allow reading of SSv5 streams stored in ADLS Gen1. To enable this feature, add `-on EnableReadSSV5OnAdlsGen1` in the nebula parameter when submitting the job, or add `SET @@EnableReadSSV5OnAdlsGen1 = true` at the top of the main script.

**Note:** Update the SCOPE SDK in order to use the `EnableReadSSV5OnAdlsGen1` flag. This feature can also be enabled at VC/account level. Please reach out to SCOPE Team for more information.

#See also
- [SELECT statement](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/SELECT)
- [FROM](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT/FROM)
- [WHERE and HAVING](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/WHERE-and-HAVING)
- [OUTPUT](/SCOPE-Language/SCOPE-Language-Reference/OUTPUT-statement)

Wiki Page: /SCOPE Language/SCOPE Tutorial/5: Reading and writing files/Extracting and extractors
#Overview
Use Extractors to convert files to rowsets, which enable users to determine how to do the conversion, handle potentially corrupt data, or yield the appropriate columns. To see code samples, view the following:
- [Code sample 1: Filtering during extraction](#code-sample-1%3A-filtering-during-extraction)
- [Code sample 2: Extracting CSV files](#code-sample-2%3A-extracting-csv-files)
- [Code sample 3: Extracting from multiple streams](#code-sample-3%3A-extracting-from-multiple-streams)

## Code sample 1: Filtering during extraction
Filtering can be performed at the time of extraction using the **HAVING** clause. 

**Note:** Users don't need to create an intermediate rowset to do additional filtering. The **WHERE** clause is NOT supported for the **EXTRACT** operator.
```scala
employeeAge40above = 
    EXTRACT 
        FirstName : string,
        LastName : string,
        Age : int
    FROM
        "/Employees.tsv"
    USING DefaultTextExtractor()
    HAVING Age > 40;
```

In general, write this as two statements.
```scala
employees = 
    EXTRACT 
        FirstName : string,
        LastName : string,
        Age : int
    FROM
        "/Employees.tsv"
    USING DefaultTextExtractor();

employeeAge40above = SELECT *
    FROM employees
    HAVING Age > 40;
```
## Code sample 2: Extracting CSV files
**DefaultTextExtractor** by default handles TSV files, but it has optional arguments that let users specify the delimiter character.
```scala
departments = 
    EXTRACT 
        DepID : string, 
        DepName : string 
    FROM "/local/Samples/SampleData/departments.txt"
    USING DefaultTextExtractor( delimiter: ',');	
```
**Protip:** **DefaultTextExtractor** is NOT a full-fledged CSV file parser since the CSV format permits special values with quotes.   To handle the full syntax, a dedicated CSV extractor is needed.

To learn more, see [DefaultTextExtractor](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/DefaultTextExtractor). 

## Code sample 3: Extracting from multiple streams
If a user has multiple streams with the same layout, they can **EXTRACT** from all of them at once by naming each stream in the **FROM** clause.
```scala
multiStream = 
    EXTRACT 
        A:string, 
        B:string, 
        C:string
    FROM  
        "stream1.tsv",
        "stream2.tsv", 
        "stream3.tsv" 
    USING DefaultTextExtractor();
```

Wiki Page: /SCOPE Language/SCOPE Tutorial/5: Reading and writing files/Outputting and outputters
# Overview 
The [**OUTPUT**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/413/OUTPUT-statement) command lets users persist a rowset into a file. Unless otherwise specified, SCOPE will use the **DefaultTextOutputter** to output a file.
## Code sample: Controlling DateTime format for DefaultTextOutputter
**DefaultTextOutputter** uses the "G" DateTime format by default (same as C#). Users can control the format used by using the `-datetime` argument.
```scala
OUTPUT TO "/local/users/<your alias>/test.txt"
USING DefaultTextOutputter( -datetime "o" )
```


Wiki Page: /SCOPE Language/SCOPE Tutorial/5: Reading and writing files/Streamsets
[[_TOC_]]
#Overview
A streamset is fundamentally about the names of files, and not about the data in the file. Users can define streamset patterns for both unstructured and structured streams. In other words, streamset syntax can be used for both the following SCOPE commands: 
- [**EXTRACT**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT) 
- [**SSTREAM**](/SCOPE-Language/SCOPE-Language-Reference/Data-formats/Structured-streams-\(SSTREAM\)) 

## Motivation
Streams are often created so that their names have some implicit structure. For example, the streams may be numbered as shown below:

- log1.txt
- log2.txt
- log3.txt 

In other cases, the streams may be named according to the date they were created:

- sales_2013-03-31.txt
- sales_2013-04-01.txt
- sales_2013-04-02.txt

Going further in the sales example, people often create folders to organize their files so that not all the logs are in one folder.

- sales/2013/03/sales-03-31.txt
- sales/2013/04/sales2013-04-01.txt
- sales/2013/04/sales2013-04-02.txt

As shown below, it is possible to use multiple streams in the **FROM** statement. 
```scala
logMultiStream = EXTRACT a:string, b:string
       FROM "/local/Samples/SampleData/StreamSets/log1.txt" ,
            "/local/Samples/SampleData/StreamSets/log2.txt" ,
            "/local/Samples/SampleData/StreamSets/log3.txt" 
       USING DefaultTextExtractor();
```

This works, but there are several issues:

- What happens when there is a large number of files?
- What happens if the user wants to get a different range?
- _The syntax above does not work with the SSTREAM keyword._
## The Solution
Cosmos has an even more powerful feature to help users deal with streams whose names follow a fixed pattern: **StreamSets**.

Before explaining the mechanics of StreamSets, see the code above transformed to use the StreamSets feature:
```scala
logStreamset = 
    EXTRACT 
        color:string, 
        hex:string,
        rgb:string,
        year_released:string,
        year_modified:string,
        notes:string
    FROM STREAMSET "/local/Samples/SampleData/StreamSets/"
         PATTERN "log%n.txt"
         RANGE __serialnum=["1", "3"]
    USING DefaultTextExtractor();
```

Here is a quick list of some of the StreamSets features:
- StreamSets work on both structured and unstructured streams
- StreamSets can be **SPARSE** allowing them to skip over missing streams
- They support ranges such as: 
o	Integer ranges (via __**serialnum**)
o	Hour ranges
o	Date ranges 
o	DateTime ranges

To learn more, see the StreamSet manual or see the StreamSet content at http://aka.ms/CosmosPresentations 

## Limitations   

The following data size and operations limitations apply to a single Steamset. You can have up to one PB/hour or use one billion appends/hour, whichever limit is reached first.

---
### Constant foldable expression in `STREAMSET`

Any constant foldable expression can be specified in the root stream name or pattern clause and more than one variable can be used. It can also be utilized on indicating a stepping function for the streamset in the RANGE clause.

``` scala 
DECLARE @pathRoot = @"somedir"; 
DECLARE @prefix = @"dir2"; 
DECLARE @pattern = @"%Y/%m/log_%d.%n"; 
DECLARE @stepMins = 30; 
E = EXTRACT a int, b:int, c:float, __datetime 
        FROM SPARSE STREAMSET string.Format("{0}/", @pathRoot) 
        PATTERN   @prefix + “__” + string.Format("{0}", @pattern) 
        RANGE __datetime=["2011-07-03","2011-07-03"](string.Format("0.00:{0}:00", @stepMins), __serialnum=["10", "20"]   // Ranges did not make it into the current release 
     USING DefaultTextExtractor; 
```

---
# How to Engage, Contribute, and Provide Feedback
- Use [MS Stack Overflow](https://aka.ms/StackOverFlowSCOPE) for basic inquiries. Tag your questions with "**scope-streamset**" for questions regarding this topic.
- For general Cosmos email discussion and community support, join [Cosmos Discussion](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join [Cosmos Announcements](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Details here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---


Wiki Page: /SCOPE Language/SCOPE Tutorial/6: Using SCOPE Studio
## Installation
1. Install [SCOPE Studio for Visual Studio](/Cosmos-Tools-and-SDKs/SCOPE-Studio). 
2. Refer to [SCOPE Studio latest releases](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3631/Release-Notes) to try the new features. 

For the latest updates and detailed information about using SCOPE Studio, see the [SCOPE Studio](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/SCOPEStudio.aspx) page or the [SCOPE Studio User Manual](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/1300/User-Manual).


Wiki Page: /SCOPE Language/SCOPE Tutorial/6: Using SCOPE Studio/Creating a new SCOPE project
# Overview

Once SCOPE Studio has been installed, users will see a new **Extensions > Scope** menu item in Visual Studio. You can check the latest version of your SCOPE extension by clicking "About SCOPE Studio".

![image.png](/.attachments/image-f485f445-d5dc-4eea-a23a-9c0dcf96133d.png)

1. To create a new project, click **File** > **New** > **Project**

![image.png](/.attachments/image-70cad141-7fdc-4a1f-8490-5a5492bcfada.png)

2. Search for the project type called **SCOPE Application** and double-click it to open a new project. Alternatively, you can opt to add a new project under a blank solution.

![image.png](/.attachments/image-c086da75-3d3b-4e0c-bc3d-a5724f2f7f0a.png)

3. On the **Configure your new project** page, click **Create**.

![image.png](/.attachments/image-a07ab86a-2345-4c6c-9d39-5075275dc895.png)

4. By default, the following appears:
   - A new SCOPE application
   - An empty SCOPE script called _Scope.script_
   - a C# code-behind file associated with the _Scope.script.cs_ script

![image.png](/.attachments/image-7dbcf606-ae12-4762-9f00-eb741a705f1f.png)

---

## See also
- [Locally running a script](/SCOPE-Language/SCOPE-Tutorial/6:-Using-SCOPE-Studio/Creating-a-new-SCOPE-project/Locally-running-a-script)

Wiki Page: /SCOPE Language/SCOPE Tutorial/6: Using SCOPE Studio/Creating a new SCOPE project/Locally running a script
# Overview

Users can run and debug a script locally just as they would a C# project – just click **F5** or click the Start option. If there are multiple projects under the same solution, make sure to properly "Set the Startup Project" to the specific SCOPE Application you want to run locally by right clicking the project and selecting the option. The selected project name will be highlighted in bold font.

If a user tries to run a script and there is an error, the **Error List** window will appear. 

Try running this empty script:

![image.png](/.attachments/image-23d2f90e-8300-4199-aaf2-51835eb3f341.png)

---

## Support BuildClusterPlan for scripts with ADLS Gen2 StreamSet

As of September 2023 release, local StreamSet support was added for ADLS Gen2. This allows users to run **BuildClusterPlan** in ScopeStudio or with scope.exe locally to compile SCOPE scripts containing remote ADLS Gen2 StreamSets.

---

## See also
- [Submitting a script and looking at the output](/SCOPE-Language/SCOPE-Tutorial/6:-Using-SCOPE-Studio/Creating-a-new-SCOPE-project/Submitting-a-script-and-looking-at-the-output)

Wiki Page: /SCOPE Language/SCOPE Tutorial/6: Using SCOPE Studio/Creating a new SCOPE project/Submitting a script and looking at the output
<font color="red"><big>**Important:**</big></font>  
If having trouble connecting or submitting jobs to Cosmos/ADLS accounts, make sure to access them within **corpnet**.  
See [Corpnet Requirement](/Accessing-Cosmos-Network/Corpnet-Requirement-when-Accessing-Cosmos) for more information.

# Overview

Previously, an empty script ran and an error appeared. Now that the solution is open and sample data is provided, try running a script to learn the basic mechanics of using SCOPE Studio.

---

See the following steps below:

1. In Visual Studio, replace **scope.script** with the code below:

```scala
searchlog = 
    EXTRACT 
        ImpressionId : int,
        UserId : int, 
        Start : DateTime, 
        Region : string, 
        Query : string, 
        Duration : int, 
        Urls : string, 
        ClickedUrls : string
    FROM "/local/Samples/SearchLog/SearchLog.txt"
    USING DefaultTextExtractor()
    ;

OUTPUT searchlog
    TO "/local/users/<your alias>/output.tsv" 
    USING DefaultTextOutputter()
    ;
```
2. To submit the script, select **Extensions > Scope >Submit Job**. Alternatively, you can also right click on your .script file and select "Submit Script".


![image.png](/.attachments/image-4435a433-cca8-4373-a106-fc111bb24024.png)
or

![image.png](/.attachments/image-83e538ab-6e50-4f9a-a3b4-23d4f10466aa.png)



3. The script should run successfully and the **Job Summary** appears.

![image.png](/.attachments/image-85a7ee58-8455-4be3-8f39-f12d4f322a0f.png)

Notice that it indicates if the output was successful (**Job Result** is **Succeeded**).
4. If a user wants to examine the output, they can navigate to their "local/users/<your alias>" folder on the sandbox to see **output.tsv**. You can also double-click on the output node to view it in Visual Studio.

**Cosmos Portal:**

![image.png](/.attachments/image-b36f051e-04f5-4b6f-b24c-43dc9b181f9e.png)

**Azure Portal:**

![image.png](/.attachments/image-adaee4ae-efda-4faf-8216-200ce4d400ea.png)

**Visual Studio:**

![image.png](/.attachments/image-6429e078-017f-4ff0-8805-e4bba58abbba.png)

---

## See also
- [Defining views](/SCOPE-Language/SCOPE-Tutorial/6:-Using-SCOPE-Studio/Defining-views)

Wiki Page: /SCOPE Language/SCOPE Tutorial/6: Using SCOPE Studio/Defining views
# Overview
A user may have written a complicated SCOPE script to get a useful rowset. Rather than inflict this complexity on others who need the same data, users have the ability to define a **View** in SCOPE.


Wiki Page: /SCOPE Language/SCOPE Tutorial/6: Using SCOPE Studio/Defining views/Understanding a simple view
# Overview
Create the simplest possible view for the **searchlog** rowset that's been available in the Cosmos sandbox. This view is exactly equivalent to that rowset (i.e. it doesn't use any special view features yet).

1. In the Cosmos sandbox, find **local>Samples>Views>** **SearchLog.view**. 



The contents of the **SearchLog.view** file are shown below.
```scala
CREATE VIEW SearchLog 
SCHEMA ( 
    ImpressionID : int,
    UserId : int, 
    Start : DateTime, 
    Region : string, 
    Query : string, 
    Duration : int, 
    Urls : string, 
    ClickedUrls : string
) AS 
BEGIN
searchlog = 
    EXTRACT 
        ImpressionID : int,
        UserId : int, 
        Start : DateTime, 
        Region : string, 
        Query : string, 
        Duration : int, 
        Urls : string, 
        ClickedUrls : string
    FROM "/local/Samples/SearchLog/SearchLog.txt"
    USING DefaultTextExtractor()
    ;
END;
```

Now consume that view:

```scala
searchlog = VIEW "/Views/SearchLog.view";
```

---

## See also
- [Parameterizing Views](/SCOPE-Language/SCOPE-Tutorial/6:-Using-SCOPE-Studio/Defining-views/Parameterizing-views)

Wiki Page: /SCOPE Language/SCOPE Tutorial/6: Using SCOPE Studio/Defining views/Parameterizing views
#Overview
Views can be parameterized to make it easy to filter its contents.

---

To filter this view by the **TimeStamp** so that the view only retrieves those records from a particular time range:
1. A View called **SearchLogParameterized.View** as shown below is also available in the Cosmos sandbox:

**Cosmos portal sandbox:**

![image.png](/.attachments/image-01974c38-966b-40de-b74d-e93168cc812b.png)

**Azure portal sandbox:**

![image.png](/.attachments/image-9d2ac944-a37e-40f9-9245-89fffeeb5351.png)


And set the contents of **SearchLogParameterized.View** to the following:

```scala
CREATE VIEW SearchLogParameterized 
SCHEMA ( 
            ImpressionId:int,
            UserId:int, 
            Start:DateTime, 
            Region:string, 
            Query:string, 
            Duration:int, 
            Urls:string, 
            ClickedUrls:string
)
PARAMS (
    start string,
    end string
)
AS BEGIN

    searchlog = VIEW "Views/SearchLog.view";

    filtered_searchlog = SELECT * 
                FROM searchlog
                WHERE Start >= DateTime.Parse(@start) AND Start < DateTime.Parse(@end).AddDays(1);
END;

```

To use this new view:

```scala
SearchLogParameterized= 
    VIEW @"Views/SearchLogParameterized.view" 
    PARAMS (
        start = "2012-02-15", 
        end = "2012-02-16"
    );

OUTPUT SearchLogParameterized
TO  @"/Output/SearchLogParameterized.tsv";
```
---

## See also
- [Defining views](/SCOPE-Language/SCOPE-Tutorial/6:-Using-SCOPE-Studio/Defining-views)

Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE
#Overview
This document is one part of the SCOPE Tutorial and focuses on extending SCOPE with C# or Python code.

## Extending SCOPE with C# 
Users can create: 

- [User-defined functions](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/User%2Ddefined-functions)
- [User-defined types](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/User%2Ddefined-types-\(UDTs\))
- [User-defined operators](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/User%2Ddefined-operators)
- [User-defined aggregates](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/User%2Ddefined-aggregates-\(UDAs\))
  - Extractors
  - Outputters
  - Processors
  - Reducers
  - Combiners

**Note:** This tutorial shows users how users *can* write custom objects, but that doesn’t mean they *should*.  In particular, users should try to avoid writing their own Aggregates, Extractors, or Combiners since they are expensive and considered as black boxes by SCOPE. Built-in SCOPE constructs and UDOs are very expressive while shared libraries exist for common scenarios not natively handled by SCOPE. User-defined functions and user-defined types are relatively common and safe. 

#See also
- [CSharp UDO extension](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/418/CSharp-UDO-extension)
- [Python UDO extension](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/420/Python-UDO-extension)

Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/User-defined functions/Custom extractors
#Overview
It is possbile to build extractors with C#.

##Code sample
Below is a sample extractor that performs a simple extraction for TSV text files (for illustrative purposes only. In real life, a user would just use **DefaultTextExtractor**)
```csharp
public class MyTsvExtractor : Extractor
{
    public override Schema Produces(string[] requested_columns, string[] args)
    {
        return new Schema(requested_columns);
    }

    public override IEnumerable<Row> Extract(StreamReader reader, Row output_row, string[] args)
    {
        char delimiter = '\t';
        string line;
        while ((line = reader.ReadLine()) != null)
        {
            var tokens = line.Split(delimiter);
            for (int i = 0; i < tokens.Length; ++i)
            {
                output_row[i].UnsafeSet(tokens[i]);
            }
            yield return output_row;
        }
    }
}
```
See how to use the extractor below:
```scala
searchlog = 
    EXTRACT IId:int, UId:int, Start:DateTime, Market:string, Query:string, DwellTime:int, Results:string, ClickedUrls:string
    FROM "/local/Samples/SearchLog/SearchLog.tsv"
    USING MyTsvExtractor();

OUTPUT searchlog TO SSTREAM "/users/{alias}/SearchLog.ss";
```
**Protip:** Users should always check whether the functionality needed is already provided by SCOPE (e.g. TSV Extractor like the one above) or a shared library before rolling out their own.

Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/User-defined functions/Custom outputters
#Overview
Users can create their own outputters. A simple example that outputs in CSV format is shown below.
##Code sample
```csharp
public class MyCsvOutputter: Outputter
{
    public override void Output(RowSet input, StreamWriter writer, string[] args)
    {
        foreach (Row row in input.Rows)
        {


            int c = 0;
            for (int i = 0; i<row.Count; i++)
            {
                if (c > 0)
                {
                    writer.Write(",");                    
                }
                row[i].Serialize(writer);
                c++;
            }
            writer.WriteLine();
            writer.Flush();
        }
    }
}
```
To use this outputter:
```scala
searchlog = VIEW "/local/Samples/Views/SearchLog.view";
OUTPUT searchlog TO "/users/{alias}/SearchLog.csv" USING MyCsvOutputter();
```



Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/User-defined functions
# Overview

For more information, see the [User-defined Functions](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/426/User-defined-functions) under SCOPE Language Reference.

Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/User-defined types (UDTs)
**In this page**
> [Overview](#overview)
> [Creating and consuming a User-defined Type (UDT)](#creating-and-consuming-a-user-defined-type-(UDT))
> [UDT serialization and deserialization](#udt-serialization-and-deserialization)

---

# Overview
Besides the normal .NET types, SCOPE also supports the creation of custom types for columns. These are very simple to create. **A key limitation** is that SCOPE output will only write out the natively-supported SCOPE types and does not support writing user-defined types to streams.

---

# Creating and consuming a User-defined type (UDT)
First, create a simple type. In this case, assume it’s important to parse out the `ClickedUrls` field into a list.

## Creating the UDT

To illustrate a User-defined type, create a wrapper around the .NET `List<T>` class.

```csharp
public class UrlList
{
    public List<string> Items;
    private static char [] sepchars = new char[] {';'};

    public UrlList(string s)
    {
        this.Items = new List<string>(s.Split(sepchars));
    }
}
```

## Consuming the UDT

1. Do the normal `EXTRACT`.

   ```scala
   searchlog = 
   EXTRACT ImpressionId : int,
            UserId : int, 
            Start : DateTime, 
            Region : string, 
            Query : string, 
            Duration : int, 
            Urls : string, 
            ClickedUrls : string
    FROM @"/local/Samples/SearchLog/SearchLog.txt"
    USING DefaultTextExtractor();
   ```

2. Create another rowset that creates a column filled with `UrlList` objects.

   ```scala
   searchlog2 = 
    SELECT ImpressionId, UserId, Start, Region, Query, Duration, new UrlList (ClickedUrls) AS CLickedUrlsList
    FROM searchlog;
   ```

3. To prove that this script really uses this new object, find the number of `ClickedUrls`.
   
   ```scala
   searchlog3 = 
    SELECT ImpressionId, UserId, Start, Region, Query, Duration, CLickedUrlsList.Items.Count AS ClickedUrlsCount
    FROM searchlog2;
   ```

## Protip
      
It is recommended to override `Equals()` and `GetHashCode()` in any user-defined type (UDT) that is created. Visit this [page](https://stackoverflow.com/questions/263400/what-is-the-best-algorithm-for-overriding-gethashcode) for some guidance on approaches that can be used.

---

# UDT serialization and deserialization

To convert the original string into a User-Defined Type (UDT), the `UrlList` constructor served the role of a deserializer, converting a string into the UDT.

SCOPE **no longer supports** legacy (`IScopeSerializableBinary`, `IScopeSerializableText`) UDT interfaces.        Some user DLLs still reference these interfaces, but not for UDT(s) used within a script. Therefore, the interfaces themselves have been retained temporarily to avoid breaking compilations, but runtime support has been removed. Future job compilations will fail for any UDT in the script that references either of these interfaces.
      
To output a UDT to stream, a serializer must be provided to convert it into a format SCOPE can natively output. This is usually done by adding a `Serialize()` method to the UDT.

As shown below, the `Serialize()` method does the opposite job of the constructor.

## User-defined type

```csharp
public class UrlList
{
    public List<string> Items;
    private static char [] sepchars = new char[] {';'};

    public UrlList(string s)
    {
        this.Items = new List<string>(s.Split(sepchars));
    }

    public static UrlList Create(string s)
    {
        return new UrlList(s);
    }

    public string Serialize()
    {
        return string.Join(";", this.Items);
    }
}
```

## Outputting the User-defined type to a stream

```scala
searchlog = 
    EXTRACT IId:int, UId:int, Start:DateTime, Market:string, Query:string, DwellTime:int, Results:string, ClickedUrls:string
    FROM @"SampleInputs\SearchLog.txt"
    USING DefaultTextExtractor();

searchlog2 = 
    SELECT IId, UId, Start, Market, Query, DwellTime, Results, new UrlList (ClickedUrls) AS CLickedUrlsList
    FROM searchlog;

searchlog3 = 
    SELECT IId, UId, Start, Market, Query, DwellTime, Results, CLickedUrlsList.Serialize() AS ClickedUrls
    FROM searchlog2;

OUTPUT searchlog3 TO @"D:\output-searchlog.txt";
```


Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/User-defined operators
#Overview
User-Defined Operators UDOs are the most powerful way of extending SCOPE. 

Using C# code users can create:
- [User-defined Extractor](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3650/User-defined-Extractor)
- [User-defined Outputter](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3654/User-defined-Outputter)
- [User-defined Processor](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3655/User-defined-Processor)
- [User-defined Reducer](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3656/User-defined-Reducer)
- [User-defined Combiner](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3653/User-defined-Combiner)
- [User-defined Applier](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3652/User-defined-Applier)
- [Aggregators](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/228/User-defined-aggregates-(UDAs))

For for information, see the [UDO Programmability Guide](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3648/UDO-Programmability-Guide) in the SCOPE Language Reference.



Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/User-defined aggregates (UDAs)
**In this page**
> [Overview](#overview)
> [UDA (mangled) suffix is not required](#uda-(mangled)-suffix-is-not-required)
> [Examples](#examples)

---

# Overview
      
User-defined aggregate enables the creation of custom aggregation operators in C#.


---

# UDA (mangled) suffix is not required
  
There is now an improved method for binding UDAs, which involves generating method overload prototypes from your class itself and allowing Roslyn to select the appropriate overload. Subsequently, this binds the name in the script to the corresponding backing class. Essentially, this enables you to name your UDA classes as you prefer, and that chosen name can be used directly within the script, omitting any suffix. Nevertheless, in cases of polymorphism, if you do not wish to use distinct names in the script—such as `Agg_1(int)` and `Agg_2(long)`—SCOPE conveniently removes the final underscore (or the entire legacy suffix, should you opt to continue naming them in that manner).


```csharp
Q = SELECT Id, MyAgg(udt), MyAgg(udt2), MyAgg(s)
     FROM Q GROUP BY Id;

public class MyAgg    : Aggregate1<MyUdt, int>         { //… }
public class MyAgg_x  : Aggregate1<MySecondUdt, int>   { //… }
public class MyAgg_y  : Aggregate1<string, int>        { //… }
```

---

# Examples

- [Creating the SUM Aggregation operator](#creating-the-sum-aggregation-operator)
- [Aggregators with multiple inputs](#aggregators-with-multiple-inputs)

---

## Creating the SUM Aggregation operator

The following shows the `SUM` aggregation operator, which is referred to as `MySum`.

### User-defined Aggregate `MySum`
```csharp
public class MySum_Double : Aggregate1<double, double>
{
    double sum = 0;

    public override void Initialize()
    {
        sum = 0;
    }

    public override void Add(double y)
    {
        sum += y;
    }

    public override double Finalize()
    {
        return sum;
    }
}
```
### Remarks
- The class is called `MySum_Double`, not `MySum`, which is significant. SCOPE requires the name to specify which type the aggregator will eventually yield.
- `MySum_Double` inherits from `Aggregate1<double, double>`. The first double indicates what input to aggregate, the second the type of the final aggregate.

### SCOPE Script

```scala
SELECT Market, MySum(Duration) AS TotalDuration
FROM searchlog
GROUP BY Market;
```

---

<span style="float: right; color: green;"><span title="This code has been verified on June 2024"><strong>✓</strong></span> Code Verified - June 2024</span></span>

## Aggregators with multiple inputs

The previous aggregator always added up one number. But sometimes there is a need to feed in multiple arguments to the aggregation. The skeleton code below accepts an integer and double and aggregates them into a string. 

### User-defined Aggregate `MyAgg2`

```csharp
public class MyAgg2_IntegerDouble : Aggregate2<int, double, string>
{
    
    System.Text.StringBuilder sb;
    public override void Initialize()
    {
        sb = new System.Text.StringBuilder();
    }

    public override void Add(int count, double value)
    {
        for (int i=0; i<count; i++)
        {
            sb.Append(value.ToString());
        }
    }

    public override string Finalize()
    {
        return sb.ToString();
    }
}
```

### SCOPE Script
```scala
SampleData  = 
    SELECT * 
    FROM (VALUES
    (2, 1.5),
    (3, 2.5),
    (1, 3.5),
    (4, 4.5)
    ) AS data(Count, Value);

rs0 = 
SELECT MyAgg2(Count, Value) AS AggregatedString
FROM SampleData;

OUTPUT rs0 TO SSTREAM @"/output/<your-alias>/searchlogProcessed.ss";
```

### Output
| AggregatedString |
|--------------|
|1.51.52.52.52.53.54.54.54.54.5|


Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/Processors
#Overview 
Processors are a way of extending Scope with C#. A processor allows users to programmatically transform a rowset. Processors can modify the values of a rowset, add columns, remove columns, remove rows, and create new rows. 

Processors can do the following:
- [Copy a rowset](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/Processors/Copy-a-rowset-processor)
- [Modify a column](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/Processors/Modify-a-column-processor)
- [Modify a schema](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/Processors/Modify-a-schema-processor)
- [Generate row processors](/SCOPE-Language/SCOPE-Tutorial/Extending-SCOPE/Processors/Generate-row-processor)




Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/Processors/Copy a rowset processor
#Overview
A processor that copies a rowset is the simplest processor. This one does nothing to the rowset; every row of input is sent back as output. 
##Code sample
Below is how the script calls a processor called **CopyProcessor**. The rowset called _searchlogCopy_ will be equivalent to _searchlogRowset_.
```scala
searchlogRowset = SELECT Market, Results
      FROM searchlog;

searchlogCopy = PROCESS searchlogRowset
      PRODUCE Market, Results
      USING CopyProcessor;
```
Now let’s look at the code for **CopyProcessor**.
```csharp
public class CopyProcessor : Processor
{
    public override Schema Produces(string[] requested_columns, string[] args, Schema input_schema)
    {
        var output_schema = input_schema.CloneWithSource();
        return output_schema;
    }	

    public override IEnumerable<Row> Process(RowSet input_rowset, Row output_row, string[] args)
    {
        foreach (Row input_row in input_rowset.Rows)
        {
            input_row.CopyTo(output_row);
            yield return output_row;
        }
    }
}
```
**Remarks**
- A processor inherits from **ScopeRuntime.Processor**.
- A processor implements two methods: **Produces()** and **Process()**.
- **Produces()** defines the schema of the output.
- **Process()** generates the output based on the input.

In this example, **Produces()** simply duplicates the input schema.
Notice that **Process()** simply duplicates each row.


Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/Processors/Modify a column processor
# Overview

The first processor built uses the **CopyTo()** method to create the output row. In the example below, modifying an existing value is shown. For example, prepend “FOO” to the **Market** field. Notice that in this case, the processor has knowledge of the schema of the input rowset.
##Code sample
```scala
searchlogRowset = SELECT Market, Results
      FROM searchlog;

searchlogProcessed = PROCESS searchlogRowset
      PRODUCE Market, Results
      USING MyProcessor;
```
```csharp
public class MyProcessor : Processor
{
    public override Schema Produces(string[] requested_columns, string[] args, Schema input_schema)
    {
        var output_schema = input_schema.Clone();
        return output_schema;
    }

    public override IEnumerable<Row> Process(RowSet input_rowset, Row output_row, string[] args)
    {
        foreach (Row input_row in input_rowset.Rows)
        {
            input_row.CopyTo(output_row);
            string market = input_row[0].String;
            output_row[0].Set( "FOO" + market );
            yield return output_row;
        }
    }
}
```


Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/Processors/Modify a schema processor
#Overview

In the previous example the **Market** column was modified. Now, instead of modifying it, create a new column and put the new value there.

First notice that **PRODUCE** clause identifies the new field:
```scala
searchlogRowset = SELECT Market, Results
      FROM searchlog;

searchlogProcessed = PROCESS searchlogRowset
      PRODUCE Market, Results, Market2
      USING MyProcessor;
```
The code for the processor now looks like this:
```csharp
public class MyProcessor : Processor
{
    public override Schema Produces(string[] requested_columns, string[] args, Schema input_schema)
    {
        var output_schema = input_schema.Clone();
        var newcol = new ColumnInfo("Market2", typeof(string));
        output_schema.Add(newcol);
        return output_schema;
    }

    public override IEnumerable<Row> Process(RowSet input_rowset, Row output_row, string[] args)
    {
        foreach (Row input_row in input_rowset.Rows)
        {
            input_row.CopyTo(output_row);
            string market = input_row[0].String;
            output_row[2].Set( "FOO" + market );
            yield return output_row;
        }
    }
}
```


Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/Processors/Generate row processor
#Overview
The examples so far has a 1-to-1 mapping between input rows and output rows. Processors can easily return more rows. For example, let's say the Results field string contains a comma-separated list or URLs. This example explains how to “break apart” a row into multiple rows so that each url is on a separate row.

For example, for this input:


| Market |  Results|
|--|--|
| en-us | A;B;C |
| en-gb | D;E;F |

This is the expected output:


| Market |Results  |
|--|--|
|  en-us | A |
|  en-us | B |
|  en-us | C |
|  en-gb |  D|
|  en-gb | E |
|  en-gb | F |


**Note:** It is preferred to do a transformation like the above with the [**CROSS APPLY**](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Splitting-and-merging-rows/Split-rows-with-CROSS-APPLY) operator. But for the purpose of this sample, we'll be using a [**Processor**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/431/Processor) for transformation of the above data.
##Code sample: Generating a row processor 
```scala
searchlogRowset = SELECT Market, Results
      FROM searchlog;

searchlogProcessed = PROCESS searchlogRowset
      PRODUCE Market, Results
      USING MyProcessor;
```
```csharp
public class MyProcessor : Processor
{
    public override Schema Produces(string[] requested_columns, string[] args, Schema input_schema)
    {
        var output_schema = input_schema.Clone();
        return output_schema;
    }

    public override IEnumerable<Row> Process(RowSet input_rowset, Row output_row, string[] args)
    {
        var splitchars = new [] {';'};

        foreach (Row input_row in input_rowset.Rows)
        {
            input_row.CopyTo(output_row);

            string results = input_row[1].String;
            var urls = results.Split(splitchars);
            foreach (string url in urls)
            {
                output_row[1].Set(url);
                yield return output_row;
            }
        }
    }
}
```
Notice now that the **yield return** is in a loop. For each input row it will yield multiple times.


Wiki Page: /SCOPE Language/SCOPE Tutorial/Extending SCOPE/Combiners
#Overview

Combiners are an advanced topic, they are included here only for completeness. Although there could be valid reasons for creating a combiner, always seek alternatives that are native SCOPE constructs.

Combiners take two rowsets as input and combine them into one output based on some matching criteria. 

##Code sample
Below is an example of the [COMBINE](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/411/COMBINE) clause used with a custom combiner called **MyCrossJoinCombiner**. However, in this scenario, JOIN is the preferred method. [COMBINE](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/411/COMBINE) is only used here to show its usage.

```scala
employees = SELECT *    
       FROM (VALUES   
               ("Noah", "1"),
                ("Sophia", "1"),
                ("Liam", "1"),
                ("Emma", "2"),
                ("Jacob", "2"),
                ("Olivia", "2"),
                ("Mason", "3"),
                ("Ava", "4"),
                ("Ethan", "4")
            ) AS employees(EmpName:string,DepID:string);

departments = SELECT *    
       FROM (VALUES   
               ("1","Engineering"),
                ("2","HR"),
                ("3","Executive"),
                ("4","Marketing")
            ) AS employees(DepID:string,DepName:string);

empDeptCombine = 	COMBINE employees WITH departments
USING MyCrossJoinCombiner ();

OUTPUT empDeptCombine TO "output.txt";
```
Now review the **MyCrossJoinCombiner**. It is the simplest combiner possible: it merges the two rowset schemas and yields every combination of rows it receives.
```csharp
public class MyCrossJoinCombiner: Combiner
{
    public override Schema Produces(
string[] requestedColumns, string[] args, 
Schema leftSchema, string leftTable, 
Schema rightSchema, string rightTable)
    {
        var tokens = new List<string>();
        foreach (var col in leftSchema.Columns)
        {
            string prefix = rightSchema.Contains(col.Name) ? leftTable : "";
            tokens.Add(string.Format("{0}{1}:{2}", prefix, col.Name, col.CLRType));
        }
        foreach (var col in rightSchema.Columns)
        {
            string prefix = leftSchema.Contains(col.Name) ? rightTable : "";
            tokens.Add(string.Format("{0}{1}:{2}", prefix, col.Name, col.CLRType));
        }
        var schemastring = string.Join(",", tokens);
        return new Schema(schemastring);
    }
	
    public override IEnumerable<Row> Combine(RowSet left, RowSet right, Row outputRow, string[] args)
    {
        var _rowList = new RowList();
        _rowList.Load(right); //  Load the right RowSet into memory
        foreach (Row leftRow in left.Rows)
        {
            leftRow.CopyTo(outputRow); // Copy the data from the leftRow to the output

            //  Copy the data from the rightRow to the output
            foreach (Row rightRow in _rowList.Rows)
            {
                for (int i = 0; i < rightRow.Count; ++i)
                {
                    rightRow[i].CopyTo(outputRow[i + leftRow.Count]);
                }
                yield return outputRow;
            }
        }
    }
}
```


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Running scripts in the cluster
#Overview

This section explains how to get access to the sandbox and submit a script in the cluster:
- [Accessing the sandbox VC](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Running-scripts-in-the-cluster/Accessing-the-sandbox-VC)
- [Uploading a stream](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Running-scripts-in-the-cluster/Uploading-a-stream)
- [Script example](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Running-scripts-in-the-cluster/Script-example)
- [Submitting the SCOPE job](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Running-scripts-in-the-cluster/Submitting-the-SCOPE-job)
- [Monitoring jobs](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Running-scripts-in-the-cluster/Monitoring-jobs) 



**Important:** The SandBox VC is often referred to, but you may use any VC that your team may have access to. 


Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Running scripts in the cluster/Accessing the sandbox VC
<font color="red"><big>**Important:**</big></font>  
If having trouble connecting or submitting jobs to Cosmos/ADLS accounts, make sure to access them within **corpnet**.  
See [Corpnet Requirement](/Accessing-Cosmos-Network/Corpnet-Requirement-when-Accessing-Cosmos) for more information.

## To request access to the Cosmos sandbox
To access the Cosmos sandbox on the Cosmos08 cluster, join the [ADL Sandbox Users Security Group](https://idwebelements.microsoft.com/GroupManagement.aspx?Group=ADLSandboxUsers&Operation=join). 



## Accessing the Cosmos portal vs. the Azure portal front ends
Cosmos is used to upload/download streams and monitor the progress of jobs and can be accessed from the Cosmos portal or the Azure portal. 

**To access Cosmos data from the Cosmos portal**
1. **Cosmos portal:** Create a folder in the [Cosmos portal](https://aad.cosmos08.osdinfra.net/cosmos/sandbox/) sandbox under `..\local\users\<your alias>`

   ![image.png](/.attachments/image-a7d6b2dd-e250-4303-96f5-a7a71150b6ac.png)

  2. Samples are available for testing under `..\sandbox\local\Samples`
   ![image.png](/.attachments/image-d12fd0c9-5695-4f7c-8417-0417560dc94b.png)
 
**To access Cosmos data from the Azure portal**
1. **Azure portal:** To access sandbox-c08 ADLA or ADLS Gen1 accounts, search for the account name **sandbox-c08** on http://aka.ms/azureportalprod.

2. Using the **Data explorer**, create a folder for your testing under `sandbox-c08\local\users\<your alias>\`. 

   ![image.png](/.attachments/image-ecc0902a-e6a4-4678-b075-4864ac6139c1.png)
3. Samples are available for testing under `sandbox-c08\local\Samples`.

   ![image.png](/.attachments/image-87f9730c-05e9-4914-baa7-2b4c9d652e20.png)

**Note:** You can access Cosmos two different ways: via the Cosmos portal or Azure portal. Both front ends represent the exact same location. Using the Azure portal, however, allows you to access the Azure ecosystem tools available for use with Cosmos. For more information, see [Azure Data Lake on Cosmos](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Azure-Data-Lake-on-Cosmos.aspx).

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Running scripts in the cluster/Uploading a stream
<font color="red"><big>**Important:**</big></font>  
If having trouble connecting or submitting jobs to Cosmos/ADLS accounts, make sure to access them within **corpnet**.  
See [Corpnet Requirement](/Accessing-Cosmos-Network/Corpnet-Requirement-when-Accessing-Cosmos) for more information.

## To upload a stream
1. Click on **..\local\users\ <your alias>** folder. 
1. Create a folder called _SampleInputs_ via **Data Operations** > **New Folder**.

![image.png](/.attachments/image-4eaae4f9-d446-49bf-b173-f8ce1ac62d8b.png)
![image.png](/.attachments/image-785f52a0-9216-44b9-8ad4-76ae83f7fe3d.png)
![image.png](/.attachments/image-a335c7fd-819d-49dd-b5f2-c95eb45bb7d8.png)

3. Navigate to the **SampleInputs** folder, which is empty.

![image.png](/.attachments/image-766e8f09-3cdb-4c96-a57d-19cba707ae0d.png)

4. To upload a stream to your new **SampleInputs** folder, Select **Data Operations** > **Upload**.

![image.png](/.attachments/image-07771aa3-0c6f-4799-8769-3e9ca32a2391.png)

5. Click the **Select files** button.

![image.png](/.attachments/image-5bd762a0-555d-4e55-97c0-860fb3ba1be7.png)

6. On the **Choose File to Upload** dialog box, select **SearchLog.txt** file.

![image.png](/.attachments/image-1cc6780c-1925-4c96-9911-84d19a8ab18d.png)

7. Click the **Submit** button.

![image.png](/.attachments/image-781b1276-71d4-4d71-b6d2-f30a9863ee34.png)
Wait for the operation to finish. Once done, you'll see this page:

![image.png](/.attachments/image-a08dbd2c-20fa-44cd-980f-ae91f9813232.png)

Notice that the **File size (Logical)** is **0 Bytes**. This will update and be correct soon.

8. Click on the **SearchLog.txt** to view a preview:

![image.png](/.attachments/image-3a98b17a-2969-4d17-9654-6659a89dbc6e.png)

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Running scripts in the cluster/Script example
##Example
Enter the following simple script into SCOPE Studio:
```scala
searchlog = 
    EXTRACT ImpressionId : int,
            UserId : int, 
            Start : DateTime, 
            Region : string, 
            Query : string, 
            Duration : int, 
            Urls : string, 
            ClickedUrls : string
    FROM "/local/Samples/SearchLog/SearchLog.txt"
    USING DefaultTextExtractor();

OUTPUT searchlog
  TO "/local/users/@@alias@@/SampleOutputs/output.tsv" 
  USING DefaultTextOutputter();
```

**Note:** The path separator character is forward slash / rather than a backslash \



Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Running scripts in the cluster/Submitting the SCOPE job
<font color="red"><big>**Important:**</big></font>  
If having trouble connecting or submitting jobs to Cosmos/ADLS accounts, make sure to access them within **corpnet**.  
See [Corpnet Requirement](/Accessing-Cosmos-Network/Corpnet-Requirement-when-Accessing-Cosmos) for more information.

## To submit a SCOPE job
1. To submit the job, click **Extensions** > **Scope** > **Submit SCOPE Job**.

![submit_job.png](/.attachments/submit_job-9137417d-bbd0-4e0f-8eef-2454b8347c66.png)

2. On the **Submit Job** box, type a name under **Friendly Name** and click **Submit**. To set parameters, click **Set** and enclose your parameters in quotes.

![image.png](/.attachments/image-558048bf-c6b8-4248-aadd-59e32ad2386a.png)


3. When the submission has been completed, the **Job Summary** will appear:

![image.png](/.attachments/image-21f603a9-4ba2-4668-9767-3f13eb2552d4.png)




4. To see the output, go back to the **/local/users/alias/ScopeTutorial/SampleOutputs** folder and navigate to **SampleOutputs**. Here you will see the stream.
![image.png](/.attachments/image-1aeec13d-2570-4137-ac82-c6f0eaa1c77c.png)

5. Now click on the **Output.txt** link.

![image.png](/.attachments/image-80c95f92-bdbc-436e-87a7-76f948d248e7.png)

6. View the details for the stream and a preview of some content. 

![image.png](/.attachments/image-9d71c684-9e4b-4b4b-9421-3bfd181dc156.png)

7. To download the stream, select **Data Operations > Download > Entire Stream**.

![image.png](/.attachments/image-ed6c61ba-1009-4dc7-b7f2-3a280ad8a728.png)

Wiki Page: /SCOPE Language/SCOPE Tutorial/1: Introduction to SCOPE/Running scripts in the cluster/Monitoring jobs
<font color="red"><big>**Important:**</big></font>  
If having trouble connecting or submitting jobs to Cosmos/ADLS accounts, make sure to access them within **corpnet**.  
See [Corpnet Requirement](/Accessing-Cosmos-Network/Corpnet-Requirement-when-Accessing-Cosmos) for more information.

## To monitor jobs
If you want to monitor jobs, navigate to your **View > My Jobs** folder and to see a list of the jobs you have recently submitted.

![image.png](/.attachments/image-05d015a7-15ae-4a91-8c52-fd4ef967e114.png)
![image.png](/.attachments/image-4fbdd446-c706-45ab-8b5f-cae9ba05f4d0.png)

Wiki Page: /SCOPE Language/SCOPE Language Reference
#Overview
SCOPE is a simple and powerful set of language tools for retrieving, querying, and manipulating data stored in Cosmos. The SCOPE query language is detailed in this reference and includes code samples and best practices. SCOPE queries look similar to SQL queries. Many fundamental concepts and syntactic expressions will be very familiar to those with a background in SQL; however, SCOPE is a distinct language. Many of the expectations users might have from SQL do not carry over into SCOPE.

For an introduction to using SCOPE, see the [SCOPE Tutorial](https://mscosmos.visualstudio.com/ScopeTutorial/_wiki/wikis/ScopeTutorial.wiki?pagePath=%2FSCOPE%20tutorial&pageId=66&wikiVersion=GBwikiMaster).

Browse the [Samples Git Repo](https://mscosmos.visualstudio.com/DefaultCollection/_git/CosmosSamples?path=%2FScopeLanguage) or [CosmosWiki Samples](https://mscosmos.visualstudio.com/DefaultCollection/CosmosWiki/_git/CosmosWiki?path=/CodeSamples&version=GBmain&_a=contents) for SCOPE Script Examples.

---
#Syntax Conventions

Note that this document also uses Extended Backus-Naur syntax notation. 

Each syntax grammar rule has a `name` followed by the `rule` body, as in:
```
name := rule.  
```

Below table lists and describes conventions that are used in the syntax diagrams here in SCOPE Language Reference.

|**Convention**| **Usage** |
|--------------|-----------|
| UPPERCASE | SCOPE keywords. |
| `[rule]`| Brakets indicate that the grammar rule `rule` occurs either 0 or 1 times. Do not type the brackets. |
| `{rule}`| Curly braces indicate that the grammar rule `rule` occurs 0 to n times. Do not type the braces. |
| `(rule)` | Parenthesis are used to nest and group grammar rules. Do not type the parenthesis. |
| `rule1` \| `rule2` | The vertical line represents a choice between `rule1` or `rule2`. It binds weaker than any of the other grammar rules. You can use only one of the items. |
| `'abc'` | Literal keyword `abc`. |
| ; | SCOPE statement terminator.

---
# SCOPE Script

A SCOPE script consists of a sequence of SCOPE statements.

## Syntax
<pre>
Script :=
    <a href="#statement_list">Statement_List</a>.

<span id="statement_list">Statement_List</span> :=
    { [<a href="#statement">Statement</a>] ';' }.

<span id="statement">Statement</span> :=
    <a href="#nebula_flag">Set_Nebula_Flag_Statement</a>
|   <a href="#preprocessor">Preprocessor_Statement</a>
|   <a href="#real_variable">Real_Variable_Statement</a>
|   <a href="#reference">Reference_Statement</a>
|   <a href="#using">Using_Statement</a>
|   <a href="#module">Define_Module_Statement</a>
|   <a href="#view">Create_View_Statement</a>
|   <a href="#query">Query_Statement</a>
|   <a href="#update">Update_Statement</a>
|   <a href="#delete">Delete_Statement</a>
|   <a href="#alter">Alter_Statement</a>
|   <a href="#export">Export_Statement</a>
|   <a href="#output">Output_Statement</a>
|   <a href="#cs_blocks">CS_Blocks.
</pre>

## Remarks

_**<<span id="nebula_flag">Set_Nebula_Flag_Statement</span>>**_ See [Nebula Flags](/SCOPE-Language/SCOPE-Language-Reference/@@Nebula-Flags) for more details.

_**<<span id="preprocessor">Preprocessor_Statement</span>>**_ See [DECLARE and SET](/SCOPE-Language/SCOPE-Language-Reference/Preprocessors/DECLARE-and-SET-\(Preprocessor\)) preprocessors and [IF...ELSE](/SCOPE-Language/SCOPE-Language-Reference/Preprocessors/IF...ELSE-\(Preprocessor\)) preprocessor for more details.

_**<<span id="real_variable">Real_Variable_Statement</span>>**_ See [DECLARE and SET (Real)](/SCOPE-Language/SCOPE-Language-Reference/Real,-Preprocessor,-and-Built%2Din-System-Variables/Real-variables/DECLARE-and-SET-\(Real\)) for more details.

_**<<span id="reference">Reference_Statement</span>>**_ See [REFERENCE](/SCOPE-Language/SCOPE-Language-Reference/User-defined-operators-\(UDOs\)/Clauses-and-Functions/REFERENCE) for more details.

_**<<span id="using">Using_Statement</span>>**_ See [USING](/SCOPE-Language/SCOPE-Language-Reference/User-defined-operators-\(UDOs\)/Clauses-and-Functions/USING) for more details.

_**<<span id="module">Define_Module_Statement</span>>**_ This contains the module declaration and the module components definitions. Module components like **FUNC**, **VIEW** and **PROC**. See [SCOPE Module](/SCOPE-Language/SCOPE-Language-Reference/SCOPE-Module) for more details.

_**<<span id="view">Create_View_Statement</span>>**_ See [SCOPE View](/SCOPE-Language/SCOPE-Language-Reference/SCOPE-View) for more details.

_**<<span id="query">Query_Statement</span>>**_ This contains **EXTRACT**, **SELECT**, **COMBINE**, **PROCESS**, or **REDUCE** statements. See [Query statements and expressions](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions) for more details.

_**<<span id="update">Update_Statement</span>>**_ See [UPDATE](/SCOPE-Language/SCOPE-Language-Reference/Bulk%2Dupdatable-structured-streams-\(BUSS\)-extensions/UPDATE) for more details.

_**<<span id="delete">Delete_Statement</span>>**_ See [DELETE](/SCOPE-Language/SCOPE-Language-Reference/Bulk%2Dupdatable-structured-streams-\(BUSS\)-extensions/DELETE) for more details.

_**<<span id="alter">Alter_Statement</span>>**_ See [ALTER and ALTER REBUILD](/SCOPE-Language/SCOPE-Language-Reference/Bulk%2Dupdatable-structured-streams-\(BUSS\)-extensions/ALTER-and-ALTER-REBUILD) for more details.

_**<<span id="export">Export_Statement</span>>**_ See [EXPORT statement](/SCOPE-Language/SCOPE-Language-Reference/EXPORT-statement) for more details.

_**<<span id="output">Output_Statement</span>>**_ See [OUTPUT statement](/SCOPE-Language/SCOPE-Language-Reference/OUTPUT-statement) for more details.

_**<<span id="cs_blocks">CS_Blocks</span>>**_ SCOPE script can also contain user defined C# codes by using CS Blocks. See [CS blocks](/SCOPE-Language/SCOPE-Language-Reference/User%2Ddefined-Functions/CS-blocks) for more details.

---

# How to Engage, Contribute, and Provide Feedback

- Use [MS Stack Overflow](https://aka.ms/StackOverFlowSCOPE) for basic Cosmos questions. Tag your questions with "cosmos" or "cosmos + SCOPE". (Tags are watched by the Cosmos Team)
- Send an email to scope@microsoft.com for general inquiry and support.
- For general Cosmos email discussion and community support, join [Cosmos Discussion Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join [Cosmos Announcements Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Information can be found here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---


Wiki Page: /SCOPE Language/SCOPE Language Reference/Built-in functions
# Overview

While SCOPE is using C# as its expression language and thus has a large set of the Common Language Runtime (CLR) libraries and all of C#’s operators at the user’s disposal, it also adds a couple of common built-in SCOPE functions.

The following built-in functions are available when using SCOPE:

- [**Aggregate functions**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions)
- [**Ranking functions**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Ranking-functions)
- [**Percentile functions**](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Percentile-functions)

---

## How to Engage, Contribute, and Provide Feedback

- Use [MS Stack Overflow](https://stackoverflow.microsoft.com/questions/ask?tags=scope,cosmos) for basic Cosmos questions. Tag your questions with "scope", "cosmos" or both. (Tags are watched by the Cosmos Team)
- Or send an email to scope@microsoft.com for general inquiry and support.
- For general Cosmos email discussion and community support, join the [Cosmos Discussion Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join the [Cosmos Announcements Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Information can be found here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---


## See also
- [Built-in system Extractor and Outputter](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter)
- [GROUP BY](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/SELECT/GROUP-BY)

Wiki Page: /SCOPE Language/SCOPE Language Reference/Operators/Conditional operators/Logical conditional operators
**In this page**
> [Overview](#Overview)
> [Remarks](#remarks)
> [CSharp literal SCOPE expressions](#csharp-literal-scope-expressions)
> [Examples](#examples)

---

# Overview

SCOPE has several logical operators, which are operators that work on Boolean expressions. Logical conditional operators are used to combine multiple conditions and control the flow of execution based on the evaluation of these conditions.

| **Operator** | **Description**          | **Maintains Valuation Order?** |
| ------------ | ------------------------ | ------------------------------ |
| x **&&** y   | the logical AND operator | Yes                            |
| x **AND** y  | the logical AND operator | No                             |
| x **\|\|** y | the logical OR operator  | Yes                            |
| x **OR** y   | the logical OR operator  | No                             |
| **NOT** x    | the logical NOT operator | No                             |
| **!** x      | the logical NOT operator | No                             |

---

# Remarks

- Operands of `AND` and `OR` are processed in parallel, but expressions of `&&` and `||` are processed as full expressions (with standard short circuiting rules). If users do want the short-circuiting behavior, use the [CSHARP operator](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/514/CSHARP-operator)).

- `&&` is equivalent to the SQL-style `ALL` operator

  - `ALL`(a,b, c,...,z) - evaluates to true if all predicates are true

- `||` is equivalent to the SQL-style `ANY` operator
  - `ANY`(a,b, c,...,z) - evaluates to true if at least one of the predicates are true. A [SCOPE expression](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/90/Expressions) is essentially any valid C# expression with some additional SCOPE-defined operators to join those C# expressions.

---

# CSharp literal SCOPE expressions

Examples include:

- true
- false
- "foo"
- 'c'
- 34
- 13.4

And they can be combined using traditional C# operators to form expressions that resolve to a specific .Net type:

- 1 > 2
- 34.3 \* 10

---
# Examples

- [Identifiers in the expression come from rowsets](#identifiers-in-the-expression-come-from-rowsets)
- [Invoking C# expressions methods defined on the type](#invoking-c%23-expressions-methods-defined-on-the-type)
- [Invoking methods defined from assembly](#invoking-methods-defined-from-assembly)
- [Using LINQ and Lamda expressions](#using-linq-and-lamda-expressions)

---

<span style="float: right; color: green;"><span title="This code has been verified on July 2024"><strong>✓</strong></span> Code Verified - Jul. 2024</span>

The following code samples refer to the same input data below.
## Input

```scala
data =
    SELECT *
    FROM(
        VALUES
        (
            "Smith,John",
            50,
            new int[]{1, 4, 9, 16, 25}
        )) AS T(Name: string, Score: int, Numbers: int[]);
```
---

<span style="float: right; color: green;"><span title="This code has been verified on July 2024"><strong>✓</strong></span> Code Verified - Jul. 2024</span>

## Identifiers in the expression come from rowsets



```sql
rs0 =
    SELECT (Score + 10) AS NewValue
    FROM data;
```

or

```sql
rs0 =
    SELECT (data.Score + 10) AS NewValue
    FROM data;
```

### Output: [ rs0 ]
| NewValue |
| -------- |
| 60       |

---

<span style="float: right; color: green;"><span title="This code has been verified on July 2024"><strong>✓</strong></span> Code Verified - Jul. 2024</span>

## Invoking C# expressions methods defined on the type

As with any C# expression users can call methods defined on the types:

```sql
rs0 =
    SELECT Name.ToUpper() AS NewName
    FROM data;
```

### Output: [ rs0 ]
| NewName    |
| ---------- |
| SMITH,JOHN |

---

<span style="float: right; color: green;"><span title="This code has been verified on July 2024"><strong>✓</strong></span> Code Verified - Jul. 2024</span>

## Invoking methods defined from assembly

As with any C# expression users can call helper methods defined in other assemblies:

```sql
rs0 =
    SELECT MyHelper(Name) AS NewName
    FROM data;
```

### Helper method
```cs
public static string MyHelper(string name)
{
    var names = name.Split(',');

    return names[1] + " " + names[0];
}
```

### Output: [ rs0 ]
| NewName    |
| ---------- |
| John Smith |

---

<span style="float: right; color: green;"><span title="This code has been verified on July 2024"><strong>✓</strong></span> Code Verified - Jul. 2024</span>

## Using LINQ and Lamda expressions

Even LINQ and Lambdas are supported. (In the example below assume that Numbers is of type int []. )

```sql
rs0 =
    SELECT Numbers.Where(i => i > 10).First() AS FirstNumberGreaterThanTen
    FROM data;
```

### Output: [ rs0 ]
| FirstNumberGreaterThanTen|
| ------------------------- |
| 16                        |




Wiki Page: /SCOPE Language/SCOPE Language Reference/Operators/Conditional operators
# Overview

Conditional operators give the developers a way to create logic that suits their business needs,

The following topics are covered in this section:

- [Logical conditional operators](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/Logical-conditional-operators)
- [IF operator](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/IF-operator)
- [Star (\*) operators](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/Star-(*)-operators)
- [IN operator](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/IN-operator)
- [WHERE and HAVING](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/WHERE-and-HAVING)
- [CASE...WHEN](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/CASE...WHEN-expression)
- [COALESCE](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/COALESCE-[In-preview])
- [RAISE...WHEN [In Preview]](/SCOPE-Language/SCOPE-Language-Reference/Operators/Conditional-operators/Conditional-RAISE...WHEN)

In the [**SELECT**](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/SELECT) clause to support aggregations, there are special aggregation operators available:

- [COUNT](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/COUNT)
- [SUM](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/SUM)
- [FIRST](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/FIRST)
- [LAST](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Aggregate-functions/LAST)

---

## How to Engage, Contribute, and Provide Feedback

- Use [MS Stack Overflow](https://stackoverflow.microsoft.com/questions/ask?tags=scope,cosmos) for basic Cosmos questions. Tag your questions with "scope", "cosmos" or both. (Tags are watched by the Cosmos Team)
- Or send an email to scope@microsoft.com for general inquiry and support.
- For general Cosmos email discussion and community support, join the [Cosmos Discussion Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join the [Cosmos Announcements Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Information can be found here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---


## See also

- [CSHARP operator](/SCOPE-Language/SCOPE-Language-Reference/Operators/CSHARP-operator)
- [Built-in functions](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions)


Wiki Page: /SCOPE Language/SCOPE Language Reference/Data types
# Overview

SCOPE has its own set of supported data types. These data types can be categorized into three general categories.

<hr>

## Data Type Classifications
- [**Native SCOPE data types**](/SCOPE-Language/SCOPE-Tutorial/1:-Introduction-to-SCOPE/Core-concepts/Data-types) are built-in data types that are optimized by SCOPE.

  - Can be further divided into [Scalars](/SCOPE-Language/SCOPE-Language-Reference/Data-types/Scalars) and [Complex Data Types](/SCOPE-Language/SCOPE-Language-Reference/Data-types/Complex-data-types).
  - Nullable versions are supported in native SCOPE data types--these all behave like their equivalent .NET counterpart.
  - _Performance will always be better if you use only Native SCOPE data types._

- **Other .NET framework types**
  - There are many .NET defined data types. For example, you could use _System.Uri_ as a data type in SCOPE.
  - **int[]** - an integer array versus **ARRAY\<int\>**, which is the native SCOPE equivalent to **int[]**. You should always prefer to use **ARRAY\<int\>** versus the .NET **int[]** array.
  - new **Dictionary()**, new **MyClass()**
- [**User-defined types**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/427/User-defined-types-(UDT))
  - User-defined types are .NET types that are created by a developer. For more information, see [User-defined types](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/427/User-defined-types-(UDT)).

---

## How to Engage, Contribute, and Provide Feedback

- Use [MS Stack Overflow](https://stackoverflow.microsoft.com/questions/ask?tags=scope,cosmos) for basic Cosmos questions. Tag your questions with "scope", "cosmos" or both. (Tags are watched by the Cosmos Team)
- Or send an email to scope@microsoft.com for general inquiry and support.
- For general Cosmos email discussion and community support, join the [Cosmos Discussion Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join the [Cosmos Announcements Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Information can be found here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---

## See also

- [Complex data types](/SCOPE-Language/SCOPE-Language-Reference/Data-types/Complex-data-types)
- [Scalar data types](/SCOPE-Language/SCOPE-Language-Reference/Data-types/Scalars)


Wiki Page: /SCOPE Language/SCOPE Language Reference/SCOPE Module
# Overview

Modules are a key component for Cosmos customers to build their data platforms. They allow developers to simplify how their data is consumed by others by bundling/packaging SCOPE artifacts (views, functions, and procedures) into a single entity called a _SCOPE Module_.

When a user wants to access a useful shared dataset, that user can import the appropriate module only, and all the associated artifacts will be made available via the namespace of the module.

More in-depth explanations about Modules can be found in [**Module Basics**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/758/Module-basics).

---

## Syntax

<pre>
Define_Module_Statement :=
    'DEFINE' 'MODULE' <a href="#module_name">module_name</a>
    'BEGIN'
        <a href="#module_components">module_components</a>
    'END' 'MODULE'

    <a href="#module_components_definitions">Module_Components_Definitions</a>.
</pre>

## Arguments

_**<<span id="module_name">module_name</span>>**_ is the user-defined name of the MODULE.

_**<<span id="module_components">module_components</span>>**_ are the components contained in the module.

_**<<span id="module_components_definitions">Module_Components_Definitions</span>>**_ are the components and how they are defined to be used in the MODULE.

---


Modules can contain any of the following components:

- [Functions (FUNC)](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/544/FUNC)
- [Views (VIEW)](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/577/VIEW)
- [Procedures (PROC)](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/579/PROC)
- [References (REFERENCE)](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/759/REFERENCE)
- [Scalar variables (CONST)](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3162/CONST-variables)
- [MODULE Parameters](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/3472/MODULE-Parameters)

For more information, see the [Modules code samples](https://mscosmos.visualstudio.com/DefaultCollection/_git/CosmosSamples?path=%2FScopeLanguage%2FScope.Modules.RowsetTransformer&version=GBmaster) in the Git Repo. You can also access the [SCOPE Modules](https://microsoft.sharepoint.com/:w:/r/teams/CosmosBDP/_layouts/15/Doc.aspx?sourcedoc=%7B9DC9BAF8-E085-4B9F-B992-58883C0A7336%7D&file=Scope-Modules.docx&action=default&mobileredirect=true) document.

---

## How to Engage, Contribute, and Provide Feedback

- Use [MS Stack Overflow](https://stackoverflow.microsoft.com/questions/ask?tags=scope,cosmos) for basic Cosmos questions. Tag your questions with "scope", "cosmos" or both. (Tags are watched by the Cosmos Team)
- Or send an email to scope@microsoft.com for general inquiry and support.
- For general Cosmos email discussion and community support, join the [Cosmos Discussion Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join the [Cosmos Announcements Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Information can be found here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---

## See also

- [VIEW](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/531/SCOPE-View)
- [User defined operators (UDOs)](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/403/User-defined-operators-(UDOs))
- [Windowing](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/306/Windowing)


Wiki Page: /SCOPE Language/SCOPE Language Reference/Preprocessors
# Overview

The preprocessor is a special, limited language that is fully interpreted by SCOPE before the script is compiled. All statements starting with **#** are preprocessor statements.

Like preprocessors in other languages, the SCOPE preprocessor allows you do to several things:

- Define values that can be reused in your script -- these are the preprocessor parameters that are created via the [**#DECLARE**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/569/DECLARE-and-SET-(Preprocessor)) keyword. Remember that reserved keywords cannot be used as variable names in SCOPE.
- Set values using the [**#SET**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/569/DECLARE-and-SET-(Preprocessor)) keyword.
- Switch between alternating sections of code depending on some condition using the [**#IF**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/571/IF...ELSE-(Preprocessor)) and [**#ELSE**](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/571/IF...ELSE-(Preprocessor)) keywords.

<hr>

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>
## Local versus remote

To facilitate development and debugging, you can use the **#IF** preprocessor directive to control the value **#DECLARE** statements, depending on which environment the script is running.

For example, you may have a very large dataset for production use, but may want to use a very small subset locally for development. Below, you can see how the processor can be used to use the correct input dataset depending on the location of the running script.

```scala
#IF(LOCAL)
     #DECLARE inputfile string = "/input.tsv";
#ELSE
     #DECLARE inputfile string = "/local/users/<your alias>/sampledata/input.tsv";
#ENDIF
```


## Preprocessors support all SCOPE Expressions


SCOPE leverages Roslyn binding evaluation stack, which SCOPE compiler front end uses, to support all recently added SCOPE expressions. (i.e.: BETWEEN, IN, ASSERT, CASE, COALESCE, STRUCT\<T\>, etc)

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>
### Code Sample

```scala
// #PP supports all SCOPE expressions (modulo user-code).
#DECLARE @v = @date BETWEEN @startDate AND @endDate
              ? @date
              : @startDate;
```


## Preprocessors support Complex Data Types (<font color="red">**NEW!**</font>)

Supports complex data types such as ARRAY<T>, MAP<K, V>, STRUCT<T>

<span style="float: right; color: green;"><span title="This code has been verified on August 2022"><strong>✓</strong></span> Code Verified - Aug. 2022</span></span>
### Code Sample

```scala
// ARRAY
#DECLARE @array ARRAY<string> = new ARRAY<string>() {"The quick brown fox", "the lazy dog"};

// MAP
#DECLARE @map MAP<int, string> = new MAP<int, string>() {{1, "abc"}, {2, "xyz"}};

// STRUCT
#DECLARE @struct = new STRUCT {Company = "Microsoft Corp", Address = new ARRAY<string> {"One Microsoft Way", "Redmond", "WA", "98052"}};
```

_**Note:** The pre-processor is still evaluated prior to script parsing (ie: before user code/resources are loaded/resolved), so it continues to have the requirement of not to support any user code._

---

## Preprocessor Batching

Preprocessor have been completely redesigned to evaluate in batches. Batches are determined by expressions that can be evaluated together, including those with variable dependencies upon each other. In fact, all **IF**/**ELSEIF** conditions can also be bound together (including across disjoint **IF**s of the same level), given that the evaluation is guarded. So, the only construct that breaks the batch (i.e. requires the prior batch to be evaluated), are **DECLARE**/**SET**s with an **IF**/**ELSEIF** branch that are referenced later, outside that statement. Although even in that case, all those statements can still be batched in that same scope together.

In practical terms, instead of spending O(N) time (where N is the number of expressions), which can be 10-120 seconds of pre-processor time for many jobs, it is now only spending O(C), where C is a constant not related to the number of expressions, but solely related to the nested conditional branches (and dependencies on those variables outside that level). For most jobs, this translates into over a 10x improvement, as most jobs have 100(s) of expression evaluation calls, those typically are now reduced to less than 10 batches, on average. However, the batches don’t scale linear with the jobs, as larger jobs (i.e. 1000(s) expressions across all MODULEs, VIEWs, FUNCS, …) were seeing most of them have less than 50 or so batches. Some of jobs in the percentile tail (many of them have generated expressions), were seeing a single job with over 7K expressions in a single batch! A very noticeable reduction for most jobs, and even more so as the job increases in size.

![Picture1.png](/.attachments/Picture1-cce37147-c6b5-4f2d-aa68-1090dc9e0e68.png)

---

## How to Engage, Contribute, and Provide Feedback

- Use [MS Stack Overflow](https://stackoverflow.microsoft.com/questions/ask?tags=scope,cosmos) for basic Cosmos questions. Tag your questions with "scope", "cosmos" or both. (Tags are watched by the Cosmos Team)
- Or send an email to scope@microsoft.com for general inquiry and support.
- For general Cosmos email discussion and community support, join the [Cosmos Discussion Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join the [Cosmos Announcements Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Information can be found here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---

## See also

- [DECLARE and SET (Preprocessor)](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/569/DECLARE-and-SET-(Preprocessor))
- [IF...ELSE (Preprocessor)](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/571/IF...ELSE-(Preprocessor))

Wiki Page: /SCOPE Language/SCOPE Language Reference/Built-in functions/Built-in system Extractor and Outputter
#Overview

The following includes the list of all supported Extractors and Outputters in the SCOPE interface:

|**Extractor**  |  **Outputter**|  **Processor**|**Combiner**  |**Reducer** |
|--|--|--|--|--|
| Extractors.SStream ||  |  |
| Extractors.Csv    |   Outputters.Csv |  |  |
| 	Extractors.Tsv |Outputters.Tsv |  |  |
| Extractors.Text |Outputters.Text |  |  |
| Extractors.Parquet |  Outputters.Parquet |  |  |
| Extractors.Orc| Outputters.Orc |  |  |
|Extractors.Python|  Outputters.Python|Processors.Python  | Combiners.Python |Reducers.Python  |  
|Extractors.Json|  |Processors.Json  |  | |

The following system objects are already built-in to the SCOPE:
- [Built-in Extractors](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/Built%2Din-Extractors)
- [Built-in Outputters](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/Built%2Din-Outputters)
- [Built-in type conversions](/SCOPE-Language/SCOPE-Language-Reference/Built%2Din-functions/Built%2Din-system-Extractor-and-Outputter/Built%2Din-type-conversions) 

**Note**: All SCOPE UDOs are in production and are available without specifying a flag. This includes: Extractors.SStream, .Csv, .Tsv, .Text, .Parquet, .Orc, and *.Python.

---

## How to Engage, Contribute, and Provide Feedback

- Use [MS Stack Overflow](https://stackoverflow.microsoft.com/questions/ask?tags=scope,cosmos) for basic Cosmos questions. Tag your questions with "scope", "cosmos" or both. (Tags are watched by the Cosmos Team)
- Or send an email to scope@microsoft.com for general inquiry and support.
- For general Cosmos email discussion and community support, join the [Cosmos Discussion Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join)
- For Cosmos service announcements, join the [Cosmos Announcements Group](http://idwebelements/GroupManagement.aspx?Group=CosmDisc&Operation=join).
- [More Contact Information can be found here at Sharepoint](https://microsoft.sharepoint.com/teams/CosmosBDP/SitePages/Community-resources.aspx)

---

## See also

- [EXTRACT](/SCOPE-Language/SCOPE-Language-Reference/Query-statements-and-expressions/EXTRACT)
- [OUTPUT](/SCOPE-Language/SCOPE-Language-Reference/OUTPUT-statement)

Wiki Page: /SCOPE Language/SCOPE Language Reference/Query statements and expressions/SELECT/Windowing
**In this page**
> [Overview](#overview)
> [Windowing function sharing computation](#windowing-function-sharing-computation)
> [Examples](#examples)
---


# Overview

A windowing function is a function whose value is computed from multiple rows (the window defined by the [`OVER`](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/360/OVER-clause) clause) instead of just the current row. _Partition_ in the context of a windowing function has nothing to do with partitioning of data in Cosmos.

## Types of windowing functions

| **Function**                                                                                | **Description**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Aggregate functions](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/1058/Aggregate-functions)   | An aggregator will compute a single result value over a group of values and will have an identity value for the case that the group is empty. They include [_reporting_](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/322/Reporting) aggregate functions such as [`SUM`](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/328/SUM) or [`AVG`](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/356/AVG), [_moving_](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/326/Moving) aggregate functions, and [_cumulative_](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/1062/Cumulative) aggregate functions. |
| [Ranking functions](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/312/Ranking-functions)       | Returns a ranking value for each row in a partition. Examples include [`DENSE_RANK`](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/337/DENSE_RANK), [`ROW_NUMBER`](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/333/ROW_NUMBER), [`NTILE`](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/316/NTILE), and [`RANK`](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/335/RANK).                                                                                                                                                 |
| [Percentile functions](https://mscosmos.visualstudio.com/CosmosWiki/_wiki/wikis/Cosmos.wiki/314/Percentile-functions) | Percentile functions compute an aggregate value based on a group of rows. However, unlike aggregate functions, they can return multiple rows for each group.                                                                                                                                                                                                                                                                                                                                                                                                                                    |

---



# Windowing function sharing computation

Shared computations among set of windowing functions appearing together in query are automatically detected. This results in fewer data shuffle operations and significantly reducing the running time.

In the example below, optimizer will group windowing function with same partitioning requirement together thus shuffling data only twice.

``` sql
Rs1= SELECT A, B, C,  
       SUM(C) OVER(PARTITION BY A) AS Id1, 
       MAX(B) OVER (PARTITION BY C) AS Id2 
     FROM Rs0; 

Rs2 = SELECT *, 
        MIN(B) OVER (PARTITION BY A) AS Id3,  
        AVG(B) OVER (PARTITION BY C) AS Id4 
      FROM Rs1; 
```

---

# Examples

Find more code samples in [_Scope.WindowingFunctions_](https://mscosmos.visualstudio.com/DefaultCollection/_git/CosmosSamples?path=%2FScopeLanguage%2FScope.WindowingFunctions&version=GBmaster) in [CosmosSamples](https://mscosmos.visualstudio.com/DefaultCollection/_git/CosmosSamples).

- [Accessing querylog data](#accessing-querylog-data)
- [Accessing employees data](#accessing-employees-data)

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>

## Input Dataset

The sample code includes a module called _Demo.module_. It contains two views used for the sample data.

```scala
DEFINE MODULE Demo

BEGIN
    VIEW QueryLog
        RETURN ROWSET(Query:string,Latency:int,Vertical:string)
        PARAMS ();
    VIEW Employees
        RETURN ROWSET(EmpID:int,EmpName:string,DeptName:string,DeptID:int,Salary:int)
        PARAMS ();
END MODULE

VIEW QueryLog
    RETURN ROWSET(Query:string,Latency:int,Vertical:string)
    PARAMS ()
BEGIN
    data =
        SELECT *
        FROM (VALUES
            ("Banana",300,"Image"),
            ("Cherry",300,"Image"),
            ("Durian",500,"Image"),
            ("Apple",100,"Web"),
            ("Fig",200,"Web"),
            ("Papaya",200,"Web"),
            ("Avocado",300,"Web"),
            ("Cherry",400,"Web"),
            ("Durian",500,"Web")
        ) AS data(Query, Latency, Vertical);
END VIEW


VIEW Employees
    RETURN ROWSET(EmpID:int,EmpName:string,DeptName:string,DeptID:int,Salary:int)
    PARAMS ()
BEGIN
    data = SELECT *
       FROM (VALUES
               (1,"Noah","Engineering",100,10000),
                (2,"Sophia","Engineering",100,20000),
                (3,"Liam","Engineering",100,30000),
                (4,"Emma","HR",200,10000),
                (5,"Jacob","HR",200,10000),
                (6,"Olivia","HR",200,10000),
                (7,"Mason","Executive",300,50000),
                (8,"Ava","Marketing",400,15000),
                (9,"Ethan","Marketing",400,10000)
            ) AS data(EmpID,EmpName,DeptName,DeptID,Salary);
END VIEW
```

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>


## Accessing querylog data
To access **querylog** data use the code below:

```scala
MODULE "Demo.module";
querylog = Demo.QueryLog();
```

### Data
| **Query** | **Latency** | **Vertical** |
|--|--|--|
|Banana | 300| Image |
| Cherry |300 | Image|
| Durian |500 | Image |
| Apple | 100| Web|
| Fig | 200 | Web |
| Papaya | 200| Web|
|Avocado | 300 | Web |
| Cherry| 400 | Web|
| Durian| 500| Web |

<span style="float: right; color: green;"><span title="This code has been verified on October 2021"><strong>✓</strong></span> Code Verified - Oct. 2021</span></span>


## Accessing employees data
To access **employees** data use the code below:

```scala
MODULE "Demo.module";
employees = Demo.Employees();
```

### Data
| **EmpID** | **EmpName** | **DeptName** | **DeptID**|**Salary** |
|--|--|--|--|--|
| 1 | Noah | Engineering |100 | 10000 |
| 2 | Sophia | Engineering | 100 | 20000 |
| 3 |Liam | Engineering | 100 | 30000 |
| 4 | Emma |HR | 200 | 10000 |
| 5 | Jacob | HR| 200| 10000|
| 6 | Olivia |HR | 200 |10000 |
| 7 |Mason | Executive | 300| 50000 |
| 8 |Ava | Marketing | 400 |15000 |
| 9 | Ethan|Marketing |400 | 10000 |

